#+TITLE: Some Notes on the Sample Complexity of Approximate Channel Simulation
#+author: Gergely Flamich and Lennie Wells
#+date: 07/06/2024

#+REVEAL_ROOT: https://cdn.jsdelivr.net/npm/reveal.js
# This is needed to make the speaker notes work
#+REVEAL_REVEAL_JS_VERSION: 4
#+OPTIONS: reveal_title_slide:"<h2>%t</h2><h2>%s</h2></br><h4>%a</h4><h4>%d</h4><h6>gergely-flamich.github.io</h6>"
#+OPTIONS: toc:nil
#+OPTIONS: num:nil
#+REVEAL_THEME: white
#+REVEAL_INIT_OPTIONS: slideNumber:'c/t', transition:'none'
#+REVEAL_HLEVEL:0
#+REVEAL_MATHJAX_URL: https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js
#+REVEAL_EXTRA_CSS: ./presentation_styles.css

* In Collaboration With

#+REVEAL_HTML: <img src="./img/collaborators/lennie_wells.jpg" width=33%>

* Studying channel simulation helps approximate sampling!

* Approximate Sampling
#+REVEAL_HTML: <div class="r-stack">
#+REVEAL_HTML: <img src="./img/motivation/example_1.svg" width=120% class="fragment">
#+REVEAL_HTML: <img src="./img/motivation/example_2.svg" width=120% class="fragment">
#+REVEAL_HTML: <img src="./img/motivation/example_3.svg" width=120% class="fragment">
#+REVEAL_HTML: <img src="./img/motivation/example_4.svg" width=120% class="fragment">
#+REVEAL_HTML: </div>

#+ATTR_REVEAL: :frag (appear)
If we want $TV[Q\, || \tilde{Q}] \leq \epsilon$, how big should $N$ be?

* Idea: Use exact sampler
#+ATTR_REVEAL: :frag (appear)
$K$ - selection rule of exact sampler

#+ATTR_REVEAL: :frag (appear)
\begin{align*}
TV[Q\, || \tilde{Q}] &= \mathbb{P}[K > N] \cdot TV[Q\, || P] \\
& \leq \mathbb{P}[K > N]
\end{align*}

#+ATTR_REVEAL: :frag (appear)
Block and Polyanskiy (2023):

#+ATTR_REVEAL: :frag (appear)
$$
N \geq {\color{blue}\frac{2}{1 - \epsilon} \log \left(\frac{2}{\epsilon}\right)} \exp\left(\frac{{\color{red}4} \cdot KL[Q\, ||\, P]}{\epsilon}\right)
$$


* Poisson Functional Representation
#+ATTR_REVEAL: :frag (appear)
$X_1, X_2, \dots$ where $X_i \sim P$

#+ATTR_REVEAL: :frag (appear)
Augment with Poisson process $T_1, T_2, \dots$

#+ATTR_REVEAL: :frag (appear)
Select $K = \mathrm{arg\,min}_{k \in \mathbb{N}}\left\{T_k \Big/ \frac{dQ}{dP}(X_k)\right\}$

* Poisson Functional Representation
$K = \mathrm{arg\,min}_{k \in \mathbb{N}}\left\{T_k \Big/ \frac{dQ}{dP}(X_k)\right\}$
#+REVEAL_HTML: <div class="r-stack">
#+REVEAL_HTML: <img src="./img/pfr/pfr_1.svg" width=100% class="fragment">
#+REVEAL_HTML: <img src="./img/pfr/pfr_2.svg" width=100% class="fragment">
#+REVEAL_HTML: <img src="./img/pfr/pfr_3.svg" width=100% class="fragment">
#+REVEAL_HTML: <img src="./img/pfr/pfr_4.svg" width=100% class="fragment">
#+REVEAL_HTML: </div>

* How is this useful?
# #+ATTR_REVEAL: :frag (appear)
#+REVEAL_HTML: <div class="r-stack" style="margin-bottom:-5%">
#+ATTR_REVEAL: :frag (appear)
\begin{align*}
\mathbb{P}[K > N] \color{white} = \mathbb{P}[\log K > \log N]
\leq \frac{\mathbb{E}[\log K]}{\log N} = \epsilon
\end{align*}

#+ATTR_REVEAL: :frag (appear)
\begin{align*}
\mathbb{P}[K > N] = \mathbb{P}[\log K > \log N]
\color{white} \leq \frac{\mathbb{E}[\log K]}{\log N} = \epsilon
\end{align*}

#+ATTR_REVEAL: :frag (appear)
\begin{align*}
\mathbb{P}[K > N] = \mathbb{P}[\log K > \log N]
 \leq \frac{\mathbb{E}[\log K]}{\log N} \color{white} = \epsilon
\end{align*}

#+ATTR_REVEAL: :frag (appear)
\begin{align*}
\mathbb{P}[K > N] = \mathbb{P}[\log K > \log N]
\leq \frac{\mathbb{E}[\log K]}{\log N} = \epsilon
\end{align*}
#+REVEAL_HTML: </div>

#+ATTR_REVEAL: :frag (appear)
Hence, to ensure $TV[Q\, || \tilde{Q}] \leq \epsilon$, pick
#+ATTR_REVEAL: :frag (appear)
$$
N \geq \exp\left( \frac{\mathbb{E}[\log K]}{\epsilon} \right)
$$

#+ATTR_REVEAL: :frag (appear)
Li and El Gamal (2018): $\mathbb{E}[\log K] \leq KL[Q\, ||\, P] + \mathcal{O}(1)$

* Final Result
#+ATTR_REVEAL: :frag (appear)
$$
N \geq \exp\left( \frac{KL[Q\, ||\, P] + \mathcal{O}(1)}{\epsilon} \right)
$$

#+ATTR_REVEAL: :frag (appear)
Furthermore:

#+ATTR_REVEAL: :frag (appear)
$$
\mathbb{H}[K] \leq KL[Q\, ||\, P] +  \log (KL[Q\, ||\, P] + 1) + \mathcal{O}(1)
$$

* Contributions

#+ATTR_REVEAL: :frag (appear)
1. Demonstrated that results from channel simulation can be used to improve approximate sampling bounds
2. For general $f$ - divergences, improve bound to
   $$
   \log\left(\frac{1}{(1 - \gamma) \epsilon}\right) \left(f'\right)^{-1}\left( \frac{D_f[Q\, ||\, P]}{\gamma \epsilon} \right) \quad \gamma \in (0, 1)
   $$
3. See paper for additional sampling complexity bounds.

* References
- Block, A., & Polyanskiy, Y. (2023, July). The sample complexity of approximate rejection sampling with applications to smoothed online learning. In The Thirty Sixth Annual Conference on Learning Theory (pp. 228-273).
- Li, C. T., & El Gamal, A. (2018). Strong functional representation lemma and applications to coding theorems. IEEE Transactions on Information Theory, 64(11), 6967-6978.

* More general bounds
Block and Polyanskiy (2023):
$$
N \geq {\color{blue}\frac{2}{1 - \epsilon} \log \left(\frac{2}{\epsilon}\right)} \left(f'\right)^{-1}\left(\frac{{\color{red}4} \cdot D_f[Q\, ||\, P]}{\epsilon}\right)
$$
Ours: for $\gamma \in (0, 1)$
$$
N \geq {\color{blue}\log\left(\frac{1}{(1 - \gamma) \epsilon}\right)} \left(f'\right)^{-1}\left( \frac{D_f[Q\, ||\, P]}{\gamma \epsilon} \right)
$$

