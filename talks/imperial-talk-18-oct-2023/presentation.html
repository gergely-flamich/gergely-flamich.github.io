<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8"/>
<title>An Introduction to Relative Entropy Coding</title>
<meta name="author" content="Gergely Flamich"/>
<meta name="description" content=""/>
<meta name="keywords" content=""/>
<style type="text/css">
.underline { text-decoration: underline; }
</style>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/reveal.js/dist/reveal.css"/>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/reveal.js/dist/theme/white.css" id="theme"/>

<link rel="stylesheet" href="./presentation_styles.css"/>
<script type="text/javascript" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>
<div class="reveal">
<div class="slides">
<section id="sec-title-slide"><h2>An Introduction to Relative Entropy Coding</h2><h2></h2></br><h4>Gergely Flamich</h4><h4>18/10/2023</h4><h6>gergely-flamich.github.io</h6>
</section>

<section id="slide-org12ab881">
<h2 id="org12ab881"><span class="section-number-2">1.</span> Talk Overview</h2>
<aside class="notes">
<p>
quant usually perceived <b>fundamental</b> to TC
</p>

</aside>

<ol>
<li class="fragment appear">Transform coding &amp; problems with \(\lfloor \cdot \rceil\)</li>
<li class="fragment appear">What is REC?</li>
<li class="fragment appear">How can we use REC?</li>
<li class="fragment appear">An example of a REC algorithm</li>
<li class="fragment appear">Some recent results</li>

</ol>

</section>
<section id="slide-org66cfa74">
<h2 id="org66cfa74"><span class="section-number-2">2.</span> In Collaboration With</h2>
<img src="./img/collaborators/jiajun_he.jpg" width=23% >
<img src="./img/collaborators/zongyu_guo.jpg" width=23%>
<img src="./img/collaborators/daniel_goc.jpg" width=23%>
<img src="./img/collaborators/miguel_hernandez_lobato.png" width=23%>

</section>
<section id="slide-orgfc5ae49">
<h2 id="orgfc5ae49"><span class="section-number-2">3.</span> Motivation</h2>
<div class="outline-text-2" id="text-3">
</div>
</section>
<section id="slide-orgd4473ae">
<h3 id="orgd4473ae"><span class="section-number-3">3.1.</span> Example: Lossy Image Compression</h3>
<aside class="notes">
<ul>
<li>transform coding</li>
<li>REC: replacement for quant + EC</li>
<li>second part: example of transform</li>

</ul>

</aside>


<div id="orgfe18f9f" class="figure">
<p><img src="./img/jpeg_example/transform_encoding.png" alt="transform_encoding.png" class="fragment (appear)" />
</p>
</div>


<div id="org2527362" class="figure">
<p><img src="./img/jpeg_example/transform_decoding.png" alt="transform_decoding.png" class="fragment (appear)" />
</p>
</div>

</section>
<section id="slide-orgd379abb">
<h3 id="orgd379abb"><span class="section-number-3">3.2.</span> The Setup</h3>
<p class="fragment (appear)">
Get an image \(Y \sim P_Y\)
</p>

<p class="fragment (appear)">
\(\mathbb{H}[Y]\) bits is best we can do to compress \(Y\)
</p>

<div class="problem-list">

<ul>
<li class="fragment appear">\(\mathbb{H}[Y]\) might be infinite</li>
<li class="fragment appear">\(\mathbb{H}[Y]\) finite, but \(P_Y\) complicated</li>

</ul>

</div>

</section>
<section id="slide-org90aceaa">
<h3 id="org90aceaa"><span class="section-number-3">3.3.</span> The Transform</h3>
<p class="fragment (appear)">
\(X = f(Y)\)
</p>

<aside class="notes">
<ul>
<li>assume \(f\) maps into \(\mathbb{R}^D\)</li>
<li>invertible or approximately invertible</li>

</ul>

</aside>

<ul>
<li class="fragment appear">Pick \(f\) such that \(P_X\) or \(P_{X \mid Y}\) is "nice"
<ul>
<li>DCT</li>
<li>inference network of VAE</li>

</ul></li>
<li class="fragment appear">\(\mathbb{H}[X]\) might still be infinite</li>

</ul>

</section>
<section id="slide-orge5c28cf">
<h3 id="orge5c28cf"><span class="section-number-3">3.4.</span> Quantization + Entropy Coding</h3>
<p class="fragment (appear)">
\(\hat{X} = \lfloor X \rceil\)
</p>

<p class="fragment (appear)">
\(\mathbb{H}[\hat{X}] < \infty\)
</p>

<div class="problem-list">

<ul>
<li class="fragment appear">\(\lfloor \cdot \rceil\) not differentiable</li>
<li class="fragment appear">Don't have precise control over \(P_{\hat{X} \mid Y}\)</li>

</ul>

</div>


</section>
<section id="slide-orgdb9cdc5">
<h2 id="orgdb9cdc5"><span class="section-number-2">4.</span> What is Relative Entropy Coding?</h2>
<p class="fragment (appear)">
üí° <b>stochastic</b> alternative to \(\lfloor \cdot \rceil\) &amp; entropy coding
</p>

<aside class="notes">
<ul>
<li>Talk about my research only</li>
<li>won't mention DQ</li>

</ul>

</aside>


</section>
<section id="slide-orgfecc43d">
<h3 id="orgfecc43d"><span class="section-number-3">4.1.</span> Relative Entropy Coding</h3>
<aside class="notes">
<ul>
<li>\(\epsilon\) is an RV</li>
<li>lose information stochastically</li>
<li>setup is more general than this</li>

</ul>

</aside>

<div class="idea-list">
<ul>
<li class="fragment appear">\(X = f(Y) + \epsilon\)</li>
<li class="fragment appear">Encode \(X \sim P_{X \mid Y}\)</li>

</ul>
</div>

<p class="fragment (appear)">
<b>Pros:</b>
</p>

<div class="tick-list">
<ul>
<li class="fragment appear">Can use reparameterization trick!</li>
<li class="fragment appear">Precise control over \(P_{X \mid Y}\) via \(f\) and \(\epsilon\)!</li>

</ul>
</div>

<p class="fragment (appear)">
<b>But:</b>
</p>
<div class="problem-list">
<ul>
<li class="fragment appear">How do we encode \(X\)?</li>
<li class="fragment appear">How many bits do we need?</li>

</ul>
</div>

</section>
<section id="slide-org5cef3f5">
<h3 id="org5cef3f5"><span class="section-number-3">4.2.</span> Rough Idea for Achievability</h3>
<p class="fragment (appear)">
Communication problem between Alice and Bob, who:
</p>
<ul>
<li class="fragment appear">share their PRNG seed \(S\)</li>
<li class="fragment appear">share \(P_X\) and can easily sample from it</li>

</ul>

<p class="fragment (appear)">
<b>Alice</b>
</p>
<ol>
<li class="fragment appear">Simulates \(N\) samples \(X_1, \dots, X_N \sim P_X^{\otimes N}\)</li>
<li class="fragment appear">Picks \(K \in [1:N]\) such that \(P_{X_K} \approx P_{X \mid Y}\).</li>
<li class="fragment appear">Encodes \(K\) using \(\approx \log K\) bits.</li>

</ol>

<aside class="notes">
<ul>
<li>e.g. rejection sampling: always pick last sample</li>

</ul>

</aside>

</section>
<section id="slide-org3e2606e">
<h3 id="org3e2606e"><span class="section-number-3">4.3.</span> Coding Efficiency</h3>
<p class="fragment (appear)">
When common randomness \(S\) available, there exists an algorithm, such that (Li and El Gamal, 2017):
\[
{\color{red} I[X; Y]} \leq \mathbb{H}[X \mid S] \leq {\color{red} I[X; Y]} + {\color{blue} \log (I[X; Y] + 1) + 4}
\]
</p>

<p class="fragment (appear)">
\(I[X; Y]\) can be <b>finite</b> even when \(\mathbb{H}[X]\) is <b>infinite</b>!
</p>

</section>
<section id="slide-orge526249">
<h3 id="orge526249"><span class="section-number-3">4.4.</span> Time Complexity</h3>
<div class="fragment (appear)">
\begin{align}
\mathbb{E}[K] &\geq 2^{\mathbb{E}[\log K]} \\
&\geq 2^{\mathbb{H}[X \mid S] - 1} \\
&\geq 2^{I[X; Y] - 1} \\
\end{align}

</div>

<p class="fragment (appear)">
This is <b>THE</b> limitation of REC in practice currently
</p>

</section>
<section id="slide-org09a930d">
<h2 id="org09a930d"><span class="section-number-2">5.</span> How Can We Use Relative Entropy Coding?</h2>
<p class="fragment (appear)">
üí° Think of \(P_{X, Y}\) as a generative model!
</p>

</section>
<section id="slide-org66396c7">
<h3 id="org66396c7"><span class="section-number-3">5.1.</span> Lossy Compression with Realism Constraints</h3>
<aside class="notes">
<ul>
<li>not my work, but probably most important application of REC</li>

</ul>

</aside>

<p class="fragment (appear)">
Rate-Distortion trade-off
\[
R(D) = \min_{P_{\hat{Y} \mid Y}} I[Y; \hat{Y}]\,\, \text{s.t.}\,\, \mathbb{E}[\Delta(Y, \hat{Y})] \leq D
\]
</p>
<p class="fragment (appear)">
Rate-Distortion-Perception trade-off
</p>
<div class="fragment (appear)">
\begin{align}
R(D, P) = \min_{P_{\hat{Y} \mid Y}} &\, I[Y; \hat{Y}]\,\, \text{s.t.}\\
\mathbb{E}&[\Delta(Y, \hat{Y})] \leq D \,\,\text{and}\,\, d(P_Y, P_{\hat{Y}}) \leq P
\end{align} 

</div>

</section>
<section id="slide-org57650ab">
<h3 id="org57650ab"><span class="section-number-3">5.2.</span> Lossy Compression with Realism Constraints</h3>
<ul>
<li>Theis &amp; Agustsson (2021):
<ul>
<li>REC provably better than quantization.</li>

</ul></li>
<li>Theis et al. (2022):</li>

</ul>
<img src="./img/applications/diffC.png" class="r-stretch" data-transition="appear">

</section>
<section id="slide-org9d3a53a">
<h3 id="org9d3a53a"><span class="section-number-3">5.3.</span> Model Compression</h3>
<img src="./img/applications/variational_bnn.png" class="r-stretch">
<ul>
<li class="fragment appear">Dataset \(\mathcal{D} \sim P_{\mathcal{D}}\)</li>
<li class="fragment appear">NN \(f(w, x)\) with weights \(w\) with prior \(P_w\)</li>
<li class="fragment appear">Train weight posterior \(P_{w \mid \mathcal{D}}\) using ELBO</li>
<li class="fragment appear">Encode \(w \sim P_{w \mid \mathcal{D}}\) in \(I[w; \mathcal{D}]\) bits</li>

</ul>

<p class="fragment (appear)">
Image from Blundell et al. (2015)
</p>

</section>
<section id="slide-org43f83d9">
<h3 id="org43f83d9"><span class="section-number-3">5.4.</span> Model Compression</h3>
<p>
Havasi et al. (2018): MIRACLE
</p>
<img src="./img/applications/miracle.png" class="r-stretch">

</section>
<section id="slide-orgc3c36d1">
<h3 id="orgc3c36d1"><span class="section-number-3">5.5.</span> Data Compression with INRs</h3>
<img src="./img/applications/coin.png" class="r-stretch">
<p>
Image from Dupont et al. (2021)
</p>

<p class="fragment (appear)">
<b>Problem</b>: Post-training quantization severely impacts performance!
</p>

</section>
<section id="slide-orgfbef077">
<h3 id="orgfbef077"><span class="section-number-3">5.6.</span> Compress variational INRs!</h3>
<p class="fragment (appear)">
<b>COMBINER</b>: COMpression with Bayesian Implicit Neural Representations
</p>

<p class="fragment (appear)">
<b>RECOMBINER</b>: Robust and Enhanced COMBINER
</p>

<p class="fragment (appear)">
üí°Gradient descent is the transform!
</p>

</section>
<section id="slide-org7d88ea4">
<h3 id="org7d88ea4"><span class="section-number-3">5.7.</span> Compress variational INRs!</h3>
<img src="./img/applications/recombiner_img.png" width="100%">

</section>
<section id="slide-orgdaa49c0">
<h3 id="orgdaa49c0"><span class="section-number-3">5.8.</span> Compress variational INRs!</h3>
<img src="./img/applications/recombiner.png" width="100%">

</section>
<section id="slide-org871fe32">
<h2 id="org871fe32"><span class="section-number-2">6.</span> Current limitations of REC</h2>
<div class="cross-list">
<ul>
<li class="fragment appear">Too slow (Agustsson &amp; Theis, 2020):
<ul>
<li>Average runtime of any general REC algorithm must scale at least \(2^{I[X; Y]}\)</li>

</ul></li>
<li class="fragment appear">Too limited:
<ul>
<li>Uniforms only (Agustsson &amp; Theis, 2020)</li>
<li>1D unimodal distributions only (F., 2022)</li>

</ul></li>
<li class="fragment appear">Too much codelength overhead</li>

</ul>
</div>

<p class="fragment (appear)">
<b>Open problem:</b> \(\mathcal{O}(I[X; Y])\) runtime when both \(P_{Y \mid X}\) and \(P_Y\) are multivariate Gaussian?
</p>

</section>
<section id="slide-orgb186ffe">
<h2 id="orgb186ffe"><span class="section-number-2">7.</span> Take home message: Overview and Applications</h2>
<ul>
<li class="fragment appear">REC is a stochastic compression framework</li>
<li class="fragment appear">Alternative to quantization and entropy coding</li>
<li class="fragment appear">It finds applications in:
<ul>
<li>Lossy compression with realism constraints</li>
<li>Model compression</li>
<li>Compressing Bayesian INRs</li>

</ul></li>
<li class="fragment appear">Currently still too slow or limited</li>

</ul>

</section>
<section id="slide-orgf1243e6">
<h2 id="orgf1243e6"><span class="section-number-2">8.</span> Greedy Poisson Rejection Sampling</h2>
<div class="outline-text-2" id="text-8">
</div>
</section>
<section id="slide-org28d36a6">
<h3 id="org28d36a6"><span class="section-number-3">8.1.</span> Recap of the Problem</h3>
<p class="fragment (appear)">
Correlated r.v.s \(X, Y \sim P_{X, Y}\)
</p>

<p class="fragment (appear)">
Alice receives \(Y \sim P_Y\)
</p>

<p class="fragment (appear)">
Bob wants to simulate \(X \sim P_{X \mid Y}\)
</p>

<p class="fragment (appear)">
Share common randomness \(S\)
</p>

<p class="fragment (appear)">
<b>Shorthand:</b> \(P = P_X\), \(Q = P_{X \mid Y}\)
</p>


</section>
<section id="slide-org8f978ea">
<h3 id="org8f978ea"><span class="section-number-3">8.2.</span> Poisson Processes</h3>
<ul>
<li class="fragment appear">Collection of random points in space</li>
<li class="fragment appear">Focus on spatio-temporal processes on \(\mathbb{R}^D \times \mathbb{R}^+\)</li>
<li class="fragment appear">Exponential inter-arrival times</li>
<li class="fragment appear">Spatial distribution \(P_{X \mid T}\)</li>
<li class="fragment appear">We will pick it as the common randomness!</li>

</ul>

</section>
<section id="slide-org2b1aebc">
<h3 id="org2b1aebc"><span class="section-number-3">8.3.</span> Poisson Processes</h3>
<img src="./img/pp_alg.png" class="r-stretch">

</section>
<section id="slide-org56b06f5">
<h3 id="org56b06f5"><span class="section-number-3">8.4.</span> Example with \(P_{X \mid T} = \mathcal{N}(0, 1)\)</h3>

<div id="org52a70ba" class="figure">
<p><img src="./img/pp/empty_pp.png" alt="empty_pp.png" />
</p>
</div>

</section>
<section id="slide-orgfcaa83b">
<h3 id="orgfcaa83b"><span class="section-number-3">8.5.</span> Example with \(P_{X \mid T} = \mathcal{N}(0, 1)\)</h3>

<div id="orge1d5aec" class="figure">
<p><img src="./img/pp/pp_t1.png" alt="pp_t1.png" />
</p>
</div>

</section>
<section id="slide-org3c34bba">
<h3 id="org3c34bba"><span class="section-number-3">8.6.</span> Example with \(P_{X \mid T} = \mathcal{N}(0, 1)\)</h3>

<div id="org6c927a9" class="figure">
<p><img src="./img/pp/pp_x1.png" alt="pp_x1.png" />
</p>
</div>

</section>
<section id="slide-org5e7384f">
<h3 id="org5e7384f"><span class="section-number-3">8.7.</span> Example with \(P_{X \mid T} = \mathcal{N}(0, 1)\)</h3>

<div id="org905eb59" class="figure">
<p><img src="./img/pp/pp_t1_x1.png" alt="pp_t1_x1.png" />
</p>
</div>

</section>
<section id="slide-orgd3f3fc7">
<h3 id="orgd3f3fc7"><span class="section-number-3">8.8.</span> Example with \(P_{X \mid T} = \mathcal{N}(0, 1)\)</h3>

<div id="orgae0ce4b" class="figure">
<p><img src="./img/pp/pp_t2.png" alt="pp_t2.png" />
</p>
</div>

</section>
<section id="slide-orgaf7149b">
<h3 id="orgaf7149b"><span class="section-number-3">8.9.</span> Example with \(P_{X \mid T} = \mathcal{N}(0, 1)\)</h3>

<div id="orgc1d4817" class="figure">
<p><img src="./img/pp/pp_x2.png" alt="pp_x2.png" />
</p>
</div>

</section>
<section id="slide-org8c7ad88">
<h3 id="org8c7ad88"><span class="section-number-3">8.10.</span> Example with \(P_{X \mid T} = \mathcal{N}(0, 1)\)</h3>

<div id="orgba41627" class="figure">
<p><img src="./img/pp/pp_t2_x2.png" alt="pp_t2_x2.png" />
</p>
</div>

</section>
<section id="slide-org1abf2c0">
<h3 id="org1abf2c0"><span class="section-number-3">8.11.</span> Example with \(P_{X \mid T} = \mathcal{N}(0, 1)\)</h3>

<div id="org00ea90f" class="figure">
<p><img src="./img/pp/pp_sim.png" alt="pp_sim.png" />
</p>
</div>


</section>
<section id="slide-org02e04cd">
<h3 id="org02e04cd"><span class="section-number-3">8.12.</span> Greedy Poisson Rejection Sampling</h3>
<p>
üí° Delete some of the points, encode index of the first point that remains
</p>

</section>
<section id="slide-org497762e">
<h3 id="org497762e"><span class="section-number-3">8.13.</span> GPRS with \(P = \mathcal{N}(0, 1), Q = \mathcal{N}(1, 1/16)\)</h3>

<div id="org01b254f" class="figure">
<p><img src="./img/gprs/gprs_0.png" alt="gprs_0.png" />
</p>
</div>

</section>
<section id="slide-org3fc2f2c">
<h3 id="org3fc2f2c"><span class="section-number-3">8.14.</span> GPRS with \(P = \mathcal{N}(0, 1), Q = \mathcal{N}(1, 1/16)\)</h3>

<div id="org8dd0ff8" class="figure">
<p><img src="./img/gprs/gprs_1.png" alt="gprs_1.png" />
</p>
</div>

</section>
<section id="slide-org6d59105">
<h3 id="org6d59105"><span class="section-number-3">8.15.</span> GPRS with \(P = \mathcal{N}(0, 1), Q = \mathcal{N}(1, 1/16)\)</h3>

<div id="org657c572" class="figure">
<p><img src="./img/gprs/gprs_2.png" alt="gprs_2.png" />
</p>
</div>

</section>
<section id="slide-org07e0d7c">
<h3 id="org07e0d7c"><span class="section-number-3">8.16.</span> GPRS with \(P = \mathcal{N}(0, 1), Q = \mathcal{N}(1, 1/16)\)</h3>

<div id="org4f636d9" class="figure">
<p><img src="./img/gprs/gprs_3.png" alt="gprs_3.png" />
</p>
</div>

</section>
<section id="slide-org59b8764">
<h3 id="org59b8764"><span class="section-number-3">8.17.</span> GPRS with \(P = \mathcal{N}(0, 1), Q = \mathcal{N}(1, 1/16)\)</h3>

<div id="org30e60d7" class="figure">
<p><img src="./img/gprs/gprs_4.png" alt="gprs_4.png" />
</p>
</div>

</section>
<section id="slide-org1fb63b0">
<h3 id="org1fb63b0"><span class="section-number-3">8.18.</span> GPRS with \(P = \mathcal{N}(0, 1), Q = \mathcal{N}(1, 1/16)\)</h3>

<div id="org6135903" class="figure">
<p><img src="./img/gprs/gprs_5.png" alt="gprs_5.png" />
</p>
</div>

</section>
<section id="slide-orga57e04f">
<h3 id="orga57e04f"><span class="section-number-3">8.19.</span> GPRS with \(P = \mathcal{N}(0, 1), Q = \mathcal{N}(1, 1/16)\)</h3>

<div id="org2457b15" class="figure">
<p><img src="./img/gprs/gprs_accept.png" alt="gprs_accept.png" />
</p>
</div>


</section>
<section id="slide-orgc9a2d2b">
<h3 id="orgc9a2d2b"><span class="section-number-3">8.20.</span> How to find the graph?</h3>
<p class="fragment (appear)">
\[
\varphi(x) = \int_0^{\frac{dQ}{dP}(x)} \frac{1}{w_Q(\eta) - \eta \cdot w_P(\eta)} \, d\eta,
\]
</p>
<p class="fragment (appear)">
where
\[
w_P(h) = \mathbb{P}_{Z \sim P}\left[\frac{dQ}{dP}(Z) \geq h \right]
\]
\[
w_Q(h) = \mathbb{P}_{Z \sim Q}\left[\frac{dQ}{dP}(Z) \geq h \right]
\]
</p>

</section>
<section id="slide-orgc2cb6e7">
<h3 id="orgc2cb6e7"><span class="section-number-3">8.21.</span> Analysis of GPRS</h3>
<p class="fragment (appear)">
<b>Codelength</b>
</p>
<div class="fragment (appear)">
\begin{align}
\mathbb{H}[X \mid S] &\leq I[X; Y] + \log (I[X; Y] + 1) \\
&\quad + 2 + \frac{1}{1 + I[X; Y] \cdot \ln 2}
\end{align}

</div>

<p class="fragment (appear)">
<b>Runtime</b>
</p>

<p class="fragment (appear)">
\[
\mathbb{E}[K \mid Y] = \exp(D_{\infty}[P_{X \mid Y} \Vert P_X])
\]
</p>

</section>
<section id="slide-org2717792">
<h3 id="org2717792"><span class="section-number-3">8.22.</span> Speeding up GPRS</h3>

<div id="orgd5ab339" class="figure">
<p><img src="./img/gprs/gprs_accept.png" alt="gprs_accept.png" />
</p>
</div>

</section>
<section id="slide-org06c63e1">
<h3 id="org06c63e1"><span class="section-number-3">8.23.</span> Fast GPRS with \(P = \mathcal{N}(0, 1), Q = \mathcal{N}(1, 1/16)\)</h3>

<div id="org73af378" class="figure">
<p><img src="./img/fast_gprs/fast_gprs_0.png" alt="fast_gprs_0.png" />
</p>
</div>
</section>
<section id="slide-org236f572">
<h3 id="org236f572"><span class="section-number-3">8.24.</span> Fast GPRS with \(P = \mathcal{N}(0, 1), Q = \mathcal{N}(1, 1/16)\)</h3>

<div id="orgf0bb6eb" class="figure">
<p><img src="./img/fast_gprs/fast_gprs_1.png" alt="fast_gprs_1.png" />
</p>
</div>
</section>
<section id="slide-orgb5f8e28">
<h3 id="orgb5f8e28"><span class="section-number-3">8.25.</span> Fast GPRS with \(P = \mathcal{N}(0, 1), Q = \mathcal{N}(1, 1/16)\)</h3>

<div id="org73f92a8" class="figure">
<p><img src="./img/fast_gprs/fast_gprs_2.png" alt="fast_gprs_2.png" />
</p>
</div>
</section>
<section id="slide-org9597470">
<h3 id="org9597470"><span class="section-number-3">8.26.</span> Fast GPRS with \(P = \mathcal{N}(0, 1), Q = \mathcal{N}(1, 1/16)\)</h3>

<div id="org5ba8692" class="figure">
<p><img src="./img/fast_gprs/fast_gprs_3.png" alt="fast_gprs_3.png" />
</p>
</div>
</section>
<section id="slide-orge9df2c9">
<h3 id="orge9df2c9"><span class="section-number-3">8.27.</span> Fast GPRS with \(P = \mathcal{N}(0, 1), Q = \mathcal{N}(1, 1/16)\)</h3>

<div id="org2a3aa28" class="figure">
<p><img src="./img/fast_gprs/fast_gprs_4.png" alt="fast_gprs_4.png" />
</p>
</div>
</section>
<section id="slide-orgd2639d8">
<h3 id="orgd2639d8"><span class="section-number-3">8.28.</span> Fast GPRS with \(P = \mathcal{N}(0, 1), Q = \mathcal{N}(1, 1/16)\)</h3>

<div id="org6a5b3c4" class="figure">
<p><img src="./img/fast_gprs/fast_gprs_5.png" alt="fast_gprs_5.png" />
</p>
</div>

</section>
<section id="slide-orge139242">
<h3 id="orge139242"><span class="section-number-3">8.29.</span> Analysis of faster GPRS</h3>
<p class="fragment (appear)">
Now, encode search path \(\pi\).
</p>

<p class="fragment (appear)">
\(\mathbb{H}[\pi] \leq I[X; Y] + \log(I[X; Y] + 1) + \mathcal{O}(1)\)
</p>

<p class="fragment (appear)">
\(\mathbb{E}[\lvert\pi\rvert] = \mathcal{O}(I[X; Y])\)
</p>

<p class="fragment (appear)">
This is <b>optimal</b>.
</p>

</section>
<section id="slide-org239d236">
<h2 id="org239d236"><span class="section-number-2">9.</span> Take home message: GPRS</h2>
<ul>
<li class="fragment appear">GPRS is a rejection sampler using Poisson processes</li>
<li class="fragment appear">Can be used for relative entropy coding</li>
<li class="fragment appear">Has an optimally efficient variant for 1D, unimodal distributions</li>

</ul>

</section>
<section id="slide-org5943b0f">
<h2 id="org5943b0f"><span class="section-number-2">10.</span> Some recent results</h2>
<p class="fragment (appear)">
ü§î REC: A misnomer?
</p>

</section>
<section id="slide-org5213045">
<h3 id="org5213045"><span class="section-number-3">10.1.</span> Coding Efficiency Revisited</h3>
<p class="fragment (appear)">
REC coding efficiency:
\[
{\color{red} I[X; Y]} \leq \mathbb{H}[X \mid S] \leq {\color{red} I[X; Y]} + {\color{blue} \log (I[X; Y] + 1) + 4}
\]
</p>

<p class="fragment (appear)">
Doesn't collapse onto Shannon's source coding theorem.
</p>

</section>
<section id="slide-orgbad68b1">
<h3 id="orgbad68b1"><span class="section-number-3">10.2.</span> Rewriting the KL Divergence</h3>
<div class="fragment (appear)">
\begin{align}
D_{KL}[Q || P]
&= \int_\Omega \frac{dQ}{dP}(x) \cdot \log \frac{dQ}{dP}(x) \, dP(x) \\
&= \log e + \int_0^\infty \underbrace{\mathbb{P}_{Z \sim P}\left[ \frac{dQ}{dP}(Z) \geq h \right]}_{= w_P(h)} \cdot \log h \, dh
\end{align}

</div>

</section>
<section id="slide-orgd948ab2">
<h3 id="orgd948ab2"><span class="section-number-3">10.3.</span> A New Measure of Efficiency</h3>
<p class="fragment (appear)">
\[
D_{KL}[Q || P] = \log e - \int_0^\infty w_P(h) \log \frac{1}{h} \, dh
\]
</p>

<p class="fragment (appear)">
\[
D_{CS}[Q || P] = -\int_0^\infty w_P(h) \log w_P(h) \, dh
\]
</p>

</section>
<section id="slide-org2d6ac4c">
<h3 id="org2d6ac4c"><span class="section-number-3">10.4.</span> Properties of \(D_{CS}\)</h3>
<ol>
<li class="fragment appear">\(D_{CS}[Q || P] \geq 0\), equality when \(Q = P\).</li>
<li class="fragment appear">\(D_{CS}[\delta_x || P] = -\log P(x)\).</li>
<li class="fragment appear"><p>
In the rejection sampling setup (Goc &amp; F.):
</p>
<div>
\begin{align}
D_{KL}[Q || P] &\leq D_{CS}[Q || P] \\
&\ {\color{red} \leq}\ \mathbb{H}[X \mid S, Y = y] \\
&\ {\color{blue} \leq}\ D_{CS}[Q || P] + \log(1 + e) \\
&\leq D_{KL}[Q || P] + \log(D_{KL}[Q || P] + 1) \\
& \quad\quad + \log(1 + e) + o(1)
\end{align}

</div></li>

</ol>

</section>
<section id="slide-orgc307cae">
<h3 id="orgc307cae"><span class="section-number-3">10.5.</span> Some Empirical Results I</h3>
<div class="fragment (appear)">
\begin{align}
D_{KL}[\mathcal{L}(0, b) || \mathcal{L}(0, 1)] &= b - \ln b - 1 \\
D_{CS}[\mathcal{L}(0, b) || \mathcal{L}(0, 1)] &= b - \psi\left(\frac{1}{b}\right) + \gamma - 1
\end{align}

</div>

<div id="orgc9e12d8" class="figure">
<p><img src="./img/new_results/laplace_divergences.png" alt="laplace_divergences.png" class="fragment (appear)" />
</p>
</div>

</section>
<section id="slide-orgf69483f">
<h3 id="orgf69483f"><span class="section-number-3">10.6.</span> Some Empirical Results II</h3>

<div id="orgcf54830" class="figure">
<p><img src="./img/new_results/gauss_1d_divergences.png" alt="gauss_1d_divergences.png" />
</p>
</div>

</section>
<section id="slide-org2b1af70">
<h3 id="org2b1af70"><span class="section-number-3">10.7.</span> Some Empirical Results III</h3>

<div id="orge762772" class="figure">
<p><img src="./img/new_results/gauss_nd_divergences.png" alt="gauss_nd_divergences.png" />
</p>
</div>


</section>
<section id="slide-org73a95c2">
<h2 id="org73a95c2"><span class="section-number-2">11.</span> References</h2>
<div class="outline-text-2" id="text-11">
</div>
</section>
<section id="slide-orgb150d4d">
<h3 id="orgb150d4d"><span class="section-number-3">11.1.</span> References I</h3>
<ul>
<li>E. Agustsson and L. Theis. "Universally quantized neural compression" In NeurIPS 2020.</li>
<li>C. Blundell, J. Cornebise, K. Kavukcuoglu and D. Wierstra. Weight uncertainty in neural network. In ICML 2015.</li>
<li>E. Dupont, A. Golinski, M. Alizadeh, Y. W. Teh and Arnaud Doucet. "COIN: compression with implicit neural representations" arXiv preprint arXiv:2103.03123, 2021.</li>

</ul>

</section>
<section id="slide-org3e10b65">
<h3 id="org3e10b65"><span class="section-number-3">11.2.</span> References II</h3>
<ul>
<li>G. F. ‚ÄúGreedy Poisson Rejection Sampling‚Äù NeurIPS 2023, to appear.</li>
<li>G. F.*, S. Markou*, and J. M. Hernandez-Lobato. "Fast relative entropy coding with A* coding". In ICML 2022.</li>
<li>D. Goc and G. F. ‚ÄúOn Channel Simulation Conjectures‚Äù unpublished.</li>

</ul>

</section>
<section id="slide-org543dc01">
<h3 id="org543dc01"><span class="section-number-3">11.3.</span> References III</h3>
<ul>
<li>Z. Guo*, G. F.*, J. He, Z. Chen and J. M. Hernandez Lobato, ‚ÄúCompression with Bayesian Implicit Neural Representations‚Äù NeurIPS 2023, to appear.</li>
<li>P. Harsha, R. Jain, D. McAllester, and J. Radhakrishnan, ‚ÄúThe communication complexity of correlation,‚Äù IEEE Transactions on Information Theory, vol. 56, no. 1, pp. 438‚Äì449, 2010.</li>
<li>M. Havasi, R. Peharz, and J. M. HernaÃÅndez-Lobato. "Minimal Random Code Learning: Getting Bits Back from Compressed Model Parameters" In ICLR 2019.</li>

</ul>

</section>
<section id="slide-orgd1d59c2">
<h3 id="orgd1d59c2"><span class="section-number-3">11.4.</span> References IV</h3>
<ul>
<li>J. He*, G. F.*, Z. Guo and J. M. Hernandez Lobato, ‚ÄúRECOMBINER: Robust and Enhanced Compression with Bayesian Implicit Neural Representations‚Äù unpublished.</li>
<li>C. T. Li and A. El Gamal, ‚ÄúStrong functional representation lemma and applications to coding theorems,‚Äù IEEE Transactions on Information Theory, vol. 64, no. 11, pp. 6967‚Äì6978, 2018.</li>

</ul>

</section>
<section id="slide-org877f713">
<h3 id="org877f713"><span class="section-number-3">11.5.</span> References V</h3>
<ul>
<li>L. Theis and E. Agustsson. On the advantages of stochastic encoders. arXiv preprint arXiv:2102.09270.</li>
<li>L. Theis, T. Salimans, M. D. Hoffman and F. Mentzer (2022). Lossy compression with Gaussian diffusion. arXiv preprint arXiv:2206.08889.</li>

</ul>

</section>
<section id="slide-orgbbeac38">
<h2 id="orgbbeac38"><span class="section-number-2">12.</span> Other material</h2>

<div id="orgd51bee4" class="figure">
<p><img src="./img/after_references/lossless_rec.png" alt="lossless_rec.png" />
</p>
</div>
</section>
</section>
</div>
</div>
<script src="https://cdn.jsdelivr.net/npm/reveal.js/dist/reveal.js"></script>
<script src="https://cdn.jsdelivr.net/npm/reveal.js/plugin/markdown/markdown.js"></script>
<script src="https://cdn.jsdelivr.net/npm/reveal.js/plugin/zoom/zoom.js"></script>
<script src="https://cdn.jsdelivr.net/npm/reveal.js/plugin/notes/notes.js"></script>


<script>
// Full list of configuration options available here:
// https://github.com/hakimel/reveal.js#configuration
Reveal.initialize({
plugins: [RevealMarkdown, RevealZoom, RevealNotes],
slideNumber:'c/t', transition:'none'
});

</script>
</body>
</html>
