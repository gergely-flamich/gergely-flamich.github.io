<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8"/>
<title>An Introduction to Relative Entropy Coding</title>
<meta name="author" content="Gergely Flamich"/>
<meta name="description" content=""/>
<meta name="keywords" content=""/>
<style type="text/css">
.underline { text-decoration: underline; }
</style>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/reveal.js/dist/reveal.css"/>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/reveal.js/dist/theme/white.css" id="theme"/>

<link rel="stylesheet" href="./presentation_styles.css"/>
<script type="text/javascript" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>
<div class="reveal">
<div class="slides">
<section id="sec-title-slide"><h2>An Introduction to Relative Entropy Coding</h2><h2></h2></br><h4>Gergely Flamich</h4><h4>18/10/2023</h4><h6>gergely-flamich.github.io</h6>
</section>

<section id="slide-orgdff90e5">
<h2 id="orgdff90e5"><span class="section-number-2">1.</span> Talk Overview</h2>
<aside class="notes">
<p>
quant usually perceived <b>fundamental</b> to TC
</p>

</aside>

<ol>
<li class="fragment appear">Transform coding &amp; problems with \(\lfloor \cdot \rceil\)</li>
<li class="fragment appear">What is REC?</li>
<li class="fragment appear">How can we use REC?</li>
<li class="fragment appear">An example of a REC algorithm</li>

</ol>

</section>
<section id="slide-org1182b28">
<h2 id="org1182b28"><span class="section-number-2">2.</span> In Collaboration With</h2>
<img src="./img/collaborators/jiajun_he.jpg" width=23% >
<img src="./img/collaborators/zongyu_guo.jpg" width=23%>
<img src="./img/collaborators/daniel_goc.jpg" width=23%>
<img src="./img/collaborators/miguel_hernandez_lobato.png" width=23%>

</section>
<section id="slide-org8a80768">
<h2 id="org8a80768"><span class="section-number-2">3.</span> Motivation</h2>
<div class="outline-text-2" id="text-3">
</div>
</section>
<section id="slide-org5117b5d">
<h3 id="org5117b5d"><span class="section-number-3">3.1.</span> Example: Lossy Image Compression</h3>
<aside class="notes">
<p>
transform coding
</p>

</aside>


<div id="org4692be3" class="figure">
<p><img src="./img/jpeg_example/transform_encoding.png" alt="transform_encoding.png" class="fragment (appear)" />
</p>
</div>


<div id="org148c100" class="figure">
<p><img src="./img/jpeg_example/transform_decoding.png" alt="transform_decoding.png" class="fragment (appear)" />
</p>
</div>

</section>
<section id="slide-org5ece671">
<h3 id="org5ece671"><span class="section-number-3">3.2.</span> The Setup</h3>
<p class="fragment (appear)">
Get an image \(Y \sim P_Y\)
</p>

<p class="fragment (appear)">
\(\mathbb{H}[Y]\) bits is best we can do to compress \(Y\)
</p>

<div class="problem-list">

<ul>
<li class="fragment appear">\(\mathbb{H}[Y]\) might be infinite</li>
<li class="fragment appear">\(\mathbb{H}[Y]\) finite, but \(P_Y\) complicated</li>

</ul>

</div>

</section>
<section id="slide-orgc2650a1">
<h3 id="orgc2650a1"><span class="section-number-3">3.3.</span> The Transform</h3>
<p class="fragment (appear)">
\(X = f(Y)\)
</p>

<aside class="notes">
<ul>
<li>assume \(f\) maps into \(\mathbb{R}^D\)</li>
<li>invertible or approximately invertible</li>

</ul>

</aside>

<ul>
<li class="fragment appear">Pick \(f\) such that \(P_X\) or \(P_{X \mid Y}\) is "nice"
<ul>
<li>DCT</li>
<li>inference network of VAE</li>

</ul></li>
<li class="fragment appear">\(\mathbb{H}[X]\) might still be infinite</li>

</ul>

</section>
<section id="slide-org8e9d4ec">
<h3 id="org8e9d4ec"><span class="section-number-3">3.4.</span> Quantization + Entropy Coding</h3>
<p class="fragment (appear)">
\(\hat{X} = \lfloor X \rceil\)
</p>

<p class="fragment (appear)">
\(\mathbb{H}[\hat{X}] < \infty\)
</p>

<div class="problem-list">

<ul>
<li class="fragment appear">\(\lfloor \cdot \rceil\) not differentiable</li>
<li class="fragment appear">Don't have precise control over \(P_{\hat{X} \mid Y}\)</li>

</ul>

</div>


</section>
<section id="slide-org3173138">
<h2 id="org3173138"><span class="section-number-2">4.</span> What is Relative Entropy Coding?</h2>
<p class="fragment (appear)">
üí° <b>stochastic</b> alternative to \(\lfloor \cdot \rceil\) &amp; entropy coding
</p>

<aside class="notes">
<ul>
<li>Talk about my research only</li>
<li>won't mention DQ</li>

</ul>

</aside>


</section>
<section id="slide-orgc48b3b9">
<h3 id="orgc48b3b9"><span class="section-number-3">4.1.</span> Relative Entropy Coding</h3>
<aside class="notes">
<ul>
<li>\(\epsilon\) is an RV</li>
<li>lose information stochastically</li>
<li>setup is more general than this</li>

</ul>

</aside>

<div class="idea-list">
<ul>
<li class="fragment appear">\(X = f(Y) + \epsilon\)</li>
<li class="fragment appear">Encode \(X \sim P_{X \mid Y}\)</li>

</ul>
</div>

<p class="fragment (appear)">
<b>Pros:</b>
</p>

<div class="tick-list">
<ul>
<li class="fragment appear">Can use reparameterization trick!</li>
<li class="fragment appear">Precise control over \(P_{X \mid Y}\) via \(f\) and \(\epsilon\)!</li>

</ul>
</div>

<p class="fragment (appear)">
<b>But:</b>
</p>
<div class="problem-list">
<ul>
<li class="fragment appear">How do we encode \(X\)?</li>
<li class="fragment appear">How many bits do we need?</li>

</ul>
</div>

</section>
<section id="slide-org488d239">
<h3 id="org488d239"><span class="section-number-3">4.2.</span> Rough Idea for Achievability</h3>
<p class="fragment (appear)">
Communication problem between Alice and Bob, who:
</p>
<ul>
<li class="fragment appear">share their PRNG seed \(S\)</li>
<li class="fragment appear">share \(P_X\)</li>
<li class="fragment appear">can easily sample from \(P_X\)</li>

</ul>

<p class="fragment (appear)">
<b>Alice</b>
</p>
<ol>
<li class="fragment appear">Simulates \(N\) samples \(X_1, \dots, X_N \sim P_X^{\otimes N}\)</li>
<li class="fragment appear">Picks \(K \in [1:N]\) such that \(P_{X_K} \approx P_{X \mid Y}\).</li>
<li class="fragment appear">Encodes \(K\) using \(\approx \log K\) bits.</li>

</ol>

<aside class="notes">
<ul>
<li>e.g. rejection sampling: always pick last sample</li>

</ul>

</aside>

</section>
<section id="slide-org4702a6f">
<h3 id="org4702a6f"><span class="section-number-3">4.3.</span> Coding Efficiency</h3>
<p class="fragment (appear)">
When common randomness \(S\) available, there exists an algorithm, such that (Li and El Gamal, 2017):
\[
{\color{red} I[X; Y]} \leq \mathbb{H}[X \mid S] \leq {\color{red} I[X; Y]} + {\color{blue} \log (I[X; Y] + 1) + 4}
\]
</p>

<p class="fragment (appear)">
\(I[X; Y]\) can be <b>finite</b> even when \(\mathbb{H}[X]\) is <b>infinite</b>!
</p>

</section>
<section id="slide-org0182dff">
<h3 id="org0182dff"><span class="section-number-3">4.4.</span> Time Complexity</h3>
<div class="fragment (appear)">
\begin{align}
\mathbb{E}[K] &\geq 2^{\mathbb{E}[\log K]} \\
&\geq 2^{\mathbb{H}[X \mid S] - 1} \\
&\geq 2^{I[X; Y] - 1} \\
\end{align}

</div>

<p class="fragment (appear)">
This is <b>THE</b> limitation of REC in practice currently
</p>

</section>
<section id="slide-orgf524e77">
<h2 id="orgf524e77"><span class="section-number-2">5.</span> How Can We Use Relative Entropy Coding?</h2>
<p class="fragment (appear)">
üí° Think of \(P_{X, Y}\) as a generative model!
</p>

</section>
<section id="slide-org9e0fa98">
<h3 id="org9e0fa98"><span class="section-number-3">5.1.</span> Lossy Compression with Realism Constraints</h3>
<p class="fragment (appear)">
Rate-Distortion trade-off
\[
R(D) = \min_{P_{\hat{Y} \mid Y}} I[Y; \hat{Y}]\,\, \text{s.t.}\,\, \mathbb{E}[\Delta(Y, \hat{Y})] \leq D
\]
</p>
<p class="fragment (appear)">
Rate-Distortion-Perception trade-off
</p>
<div class="fragment (appear)">
\begin{align}
R(D, P) = \min_{P_{\hat{Y} \mid Y}} &\, I[Y; \hat{Y}]\,\, \text{s.t.}\\
\mathbb{E}&[\Delta(Y, \hat{Y})] \leq D \,\,\,\,\, d(P_Y, P_{\hat{Y}}) \leq P
\end{align} 

</div>

</section>
<section id="slide-org0e23545">
<h3 id="org0e23545"><span class="section-number-3">5.2.</span> Lossy Compression with Realism Constraints</h3>
<ul>
<li>Theis &amp; Agustsson (2021):
<ul>
<li>REC provably better than quantization.</li>

</ul></li>
<li>Theis et al. (2022):</li>

</ul>
<img src="./img/applications/diffC.png" class="r-stretch" data-transition="appear">

</section>
<section id="slide-org6d3a51d">
<h3 id="org6d3a51d"><span class="section-number-3">5.3.</span> Model Compression</h3>
<img src="./img/applications/variational_bnn.png" class="r-stretch">
<ul>
<li class="fragment appear">Dataset \(\mathcal{D} \sim P_{\mathcal{D}}\)</li>
<li class="fragment appear">NN \(f(w, x)\) with weights \(w\) with prior \(P_w\)</li>
<li class="fragment appear">Train weight posterior \(P_{w \mid \mathcal{D}}\) using ELBO</li>
<li class="fragment appear">Encode \(w \sim P_{w \mid \mathcal{D}}\) in \(I[w; \mathcal{D}]\) bits</li>

</ul>

<p class="fragment (appear)">
Image from Blundell et al. (2015)
</p>

</section>
<section id="slide-org69f6ec9">
<h3 id="org69f6ec9"><span class="section-number-3">5.4.</span> Model Compression</h3>
<p>
Havasi et al. (2018): MIRACLE
</p>
<img src="./img/applications/miracle.png" class="r-stretch">

</section>
<section id="slide-org2d60d98">
<h3 id="org2d60d98"><span class="section-number-3">5.5.</span> Data Compression with INRs</h3>
<img src="./img/applications/coin.png" class="r-stretch">
<p>
Image from Dupont et al. (2021)
</p>

<p class="fragment (appear)">
<b>Problem</b>: Post-training quantization severely impacts performance!
</p>

</section>
<section id="slide-org062d7e6">
<h3 id="org062d7e6"><span class="section-number-3">5.6.</span> Compress variational INRs!</h3>
<p class="fragment (appear)">
<b>COMBINER</b>: COMpression with Bayesian Implicit Neural Representations
</p>

<p class="fragment (appear)">
<b>RECOMBINER</b>: Robust and Enhanced COMBINER
</p>

<p class="fragment (appear)">
üí°Gradient descent is the transform!
</p>

</section>
<section id="slide-org34a35bf">
<h3 id="org34a35bf"><span class="section-number-3">5.7.</span> Compress variational INRs!</h3>
<img src="./img/applications/recombiner_img.png" width="100%">

</section>
<section id="slide-orgc4b4dde">
<h3 id="orgc4b4dde"><span class="section-number-3">5.8.</span> Compress variational INRs!</h3>
<img src="./img/applications/recombiner.png" width="100%">

</section>
<section id="slide-org92e1490">
<h2 id="org92e1490"><span class="section-number-2">6.</span> Current limitations of REC</h2>
<div class="cross-list">
<ul>
<li class="fragment appear">Too slow (Agustsson &amp; Theis, 2020):
<ul>
<li>Average runtime of any general REC algorithm must scale at least \(2^{I[X; Y]}\)</li>

</ul></li>
<li class="fragment appear">Too limited:
<ul>
<li>Uniforms only (Agustsson &amp; Theis, 2020)</li>
<li>1D unimodal distributions only (F., 2022)</li>

</ul></li>
<li class="fragment appear">Too much codelength overhead</li>

</ul>
</div>

<p class="fragment (appear)">
<b>Open problem:</b> \(\mathcal{O}(I[X; Y])\) runtime when both \(P_{Y \mid X}\) and \(P_Y\) are multivariate Gaussian?
</p>

</section>
<section id="slide-org6a4a2bf">
<h2 id="org6a4a2bf"><span class="section-number-2">7.</span> Take home message: Overview and Applications</h2>
<ul>
<li class="fragment appear">REC is a stochastic compression framework</li>
<li class="fragment appear">Alternative to quantization and entropy coding</li>
<li class="fragment appear">It finds applications in:
<ul>
<li>Lossy compression with realism constraints</li>
<li>Model compression</li>
<li>Compressing Bayesian INRs</li>

</ul></li>
<li class="fragment appear">Currently still too slow or limited</li>

</ul>

</section>
<section id="slide-org515a18e">
<h2 id="org515a18e"><span class="section-number-2">8.</span> Greedy Poisson Rejection Sampling</h2>
<div class="outline-text-2" id="text-8">
</div>
</section>
<section id="slide-orgc10190b">
<h3 id="orgc10190b"><span class="section-number-3">8.1.</span> Recap of the Problem</h3>
<p class="fragment (appear)">
Correlated r.v.s \(X, Y \sim P_{X, Y}\)
</p>

<p class="fragment (appear)">
Alice receives \(Y \sim P_Y\)
</p>

<p class="fragment (appear)">
Bob wants to simulate \(X \sim P_{X \mid Y}\)
</p>

<p class="fragment (appear)">
Share common randomness \(S\)
</p>

<p class="fragment (appear)">
<b>Shorthand:</b> \(P = P_X\), \(Q = P_{X \mid Y}\)
</p>


</section>
<section id="slide-org70a47c1">
<h3 id="org70a47c1"><span class="section-number-3">8.2.</span> Poisson Processes</h3>
<ul>
<li class="fragment appear">Collection of random points in space</li>
<li class="fragment appear">Focus on spatio-temporal processes on \(\mathbb{R}^D \times \mathbb{R}^+\)</li>
<li class="fragment appear">Exponential inter-arrival times</li>
<li class="fragment appear">Spatial distribution \(P_{X \mid T}\)</li>
<li class="fragment appear">We will pick it as the common randomness!</li>

</ul>

</section>
<section id="slide-org1c7372a">
<h3 id="org1c7372a"><span class="section-number-3">8.3.</span> Poisson Processes</h3>
<img src="./img/pp_alg.png" class="r-stretch">

</section>
<section id="slide-org2d4f213">
<h3 id="org2d4f213"><span class="section-number-3">8.4.</span> Example with \(P_{X \mid T} = \mathcal{N}(0, 1)\)</h3>

<div id="org5e27d22" class="figure">
<p><img src="./img/pp/empty_pp.png" alt="empty_pp.png" />
</p>
</div>

</section>
<section id="slide-org8963dde">
<h3 id="org8963dde"><span class="section-number-3">8.5.</span> Example with \(P_{X \mid T} = \mathcal{N}(0, 1)\)</h3>

<div id="org041ae0a" class="figure">
<p><img src="./img/pp/pp_t1.png" alt="pp_t1.png" />
</p>
</div>

</section>
<section id="slide-org5d6f855">
<h3 id="org5d6f855"><span class="section-number-3">8.6.</span> Example with \(P_{X \mid T} = \mathcal{N}(0, 1)\)</h3>

<div id="orgfe3b93f" class="figure">
<p><img src="./img/pp/pp_x1.png" alt="pp_x1.png" />
</p>
</div>

</section>
<section id="slide-org28a1dce">
<h3 id="org28a1dce"><span class="section-number-3">8.7.</span> Example with \(P_{X \mid T} = \mathcal{N}(0, 1)\)</h3>

<div id="org110eee1" class="figure">
<p><img src="./img/pp/pp_t1_x1.png" alt="pp_t1_x1.png" />
</p>
</div>

</section>
<section id="slide-org53ad6c6">
<h3 id="org53ad6c6"><span class="section-number-3">8.8.</span> Example with \(P_{X \mid T} = \mathcal{N}(0, 1)\)</h3>

<div id="orgdbd95c5" class="figure">
<p><img src="./img/pp/pp_t2.png" alt="pp_t2.png" />
</p>
</div>

</section>
<section id="slide-orgca6a90f">
<h3 id="orgca6a90f"><span class="section-number-3">8.9.</span> Example with \(P_{X \mid T} = \mathcal{N}(0, 1)\)</h3>

<div id="orgc5ac1d5" class="figure">
<p><img src="./img/pp/pp_x2.png" alt="pp_x2.png" />
</p>
</div>

</section>
<section id="slide-org23634b8">
<h3 id="org23634b8"><span class="section-number-3">8.10.</span> Example with \(P_{X \mid T} = \mathcal{N}(0, 1)\)</h3>

<div id="orgb7cbe59" class="figure">
<p><img src="./img/pp/pp_t2_x2.png" alt="pp_t2_x2.png" />
</p>
</div>

</section>
<section id="slide-org91e1857">
<h3 id="org91e1857"><span class="section-number-3">8.11.</span> Example with \(P_{X \mid T} = \mathcal{N}(0, 1)\)</h3>

<div id="org7a50158" class="figure">
<p><img src="./img/pp/pp_sim.png" alt="pp_sim.png" />
</p>
</div>


</section>
<section id="slide-orgc9df2d8">
<h3 id="orgc9df2d8"><span class="section-number-3">8.12.</span> Greedy Poisson Rejection Sampling</h3>
<p>
üí° Delete some of the points, encode index of the first point that remains
</p>

</section>
<section id="slide-org40e5cce">
<h3 id="org40e5cce"><span class="section-number-3">8.13.</span> GPRS with \(P = \mathcal{N}(0, 1), Q = \mathcal{N}(1, 1/16)\)</h3>

<div id="orgcb9c1c5" class="figure">
<p><img src="./img/gprs/gprs_0.png" alt="gprs_0.png" />
</p>
</div>

</section>
<section id="slide-org81f3a87">
<h3 id="org81f3a87"><span class="section-number-3">8.14.</span> GPRS with \(P = \mathcal{N}(0, 1), Q = \mathcal{N}(1, 1/16)\)</h3>

<div id="orgfa1c056" class="figure">
<p><img src="./img/gprs/gprs_1.png" alt="gprs_1.png" />
</p>
</div>

</section>
<section id="slide-org3fc3d27">
<h3 id="org3fc3d27"><span class="section-number-3">8.15.</span> GPRS with \(P = \mathcal{N}(0, 1), Q = \mathcal{N}(1, 1/16)\)</h3>

<div id="org77c4744" class="figure">
<p><img src="./img/gprs/gprs_2.png" alt="gprs_2.png" />
</p>
</div>

</section>
<section id="slide-org4137c1d">
<h3 id="org4137c1d"><span class="section-number-3">8.16.</span> GPRS with \(P = \mathcal{N}(0, 1), Q = \mathcal{N}(1, 1/16)\)</h3>

<div id="orgc3fe580" class="figure">
<p><img src="./img/gprs/gprs_3.png" alt="gprs_3.png" />
</p>
</div>

</section>
<section id="slide-orgd3d7ef3">
<h3 id="orgd3d7ef3"><span class="section-number-3">8.17.</span> GPRS with \(P = \mathcal{N}(0, 1), Q = \mathcal{N}(1, 1/16)\)</h3>

<div id="org1589e4c" class="figure">
<p><img src="./img/gprs/gprs_4.png" alt="gprs_4.png" />
</p>
</div>

</section>
<section id="slide-orge82668f">
<h3 id="orge82668f"><span class="section-number-3">8.18.</span> GPRS with \(P = \mathcal{N}(0, 1), Q = \mathcal{N}(1, 1/16)\)</h3>

<div id="org672c4be" class="figure">
<p><img src="./img/gprs/gprs_5.png" alt="gprs_5.png" />
</p>
</div>

</section>
<section id="slide-org6572896">
<h3 id="org6572896"><span class="section-number-3">8.19.</span> GPRS with \(P = \mathcal{N}(0, 1), Q = \mathcal{N}(1, 1/16)\)</h3>

<div id="orgd8fe356" class="figure">
<p><img src="./img/gprs/gprs_accept.png" alt="gprs_accept.png" />
</p>
</div>


</section>
<section id="slide-org80e033a">
<h3 id="org80e033a"><span class="section-number-3">8.20.</span> How to find the graph?</h3>
<p class="fragment (appear)">
\[
\varphi(x) = \int_0^{\frac{dQ}{dP}(x)} \frac{1}{w_Q(\eta) - \eta \cdot w_P(\eta)} \, d\eta,
\]
</p>
<p class="fragment (appear)">
where
\[
w_P(h) = \mathbb{P}_{Z \sim P}\left[\frac{dQ}{dP}(Z) \geq h \right]
\]
\[
w_Q(h) = \mathbb{P}_{Z \sim Q}\left[\frac{dQ}{dP}(Z) \geq h \right]
\]
</p>

</section>
<section id="slide-org28bcd9d">
<h3 id="org28bcd9d"><span class="section-number-3">8.21.</span> Analysis of GPRS</h3>
<p class="fragment (appear)">
<b>Codelength</b>
</p>
<div class="fragment (appear)">
\begin{align}
\mathbb{H}[X \mid S] &\leq I[X; Y] + \log (I[X; Y] + 1) \\
&\quad + 2 + \frac{1}{1 + I[X; Y] \cdot \ln 2}
\end{align}

</div>

<p class="fragment (appear)">
<b>Runtime</b>
</p>

<p class="fragment (appear)">
\[
\mathbb{E}[K \mid Y] = \exp(D_{\infty}[P_{X \mid Y} \Vert P_X])
\]
</p>

</section>
<section id="slide-org0042638">
<h3 id="org0042638"><span class="section-number-3">8.22.</span> Speeding up GPRS</h3>

<div id="org85a33a4" class="figure">
<p><img src="./img/gprs/gprs_accept.png" alt="gprs_accept.png" />
</p>
</div>

</section>
<section id="slide-org68e632a">
<h3 id="org68e632a"><span class="section-number-3">8.23.</span> Fast GPRS with \(P = \mathcal{N}(0, 1), Q = \mathcal{N}(1, 1/16)\)</h3>

<div id="orgc44f93d" class="figure">
<p><img src="./img/fast_gprs/fast_gprs_0.png" alt="fast_gprs_0.png" />
</p>
</div>
</section>
<section id="slide-org1974f7a">
<h3 id="org1974f7a"><span class="section-number-3">8.24.</span> Fast GPRS with \(P = \mathcal{N}(0, 1), Q = \mathcal{N}(1, 1/16)\)</h3>

<div id="org11e19c1" class="figure">
<p><img src="./img/fast_gprs/fast_gprs_1.png" alt="fast_gprs_1.png" />
</p>
</div>
</section>
<section id="slide-org286ea8b">
<h3 id="org286ea8b"><span class="section-number-3">8.25.</span> Fast GPRS with \(P = \mathcal{N}(0, 1), Q = \mathcal{N}(1, 1/16)\)</h3>

<div id="org8d2cf29" class="figure">
<p><img src="./img/fast_gprs/fast_gprs_2.png" alt="fast_gprs_2.png" />
</p>
</div>
</section>
<section id="slide-org088a2d1">
<h3 id="org088a2d1"><span class="section-number-3">8.26.</span> Fast GPRS with \(P = \mathcal{N}(0, 1), Q = \mathcal{N}(1, 1/16)\)</h3>

<div id="orgde17dc3" class="figure">
<p><img src="./img/fast_gprs/fast_gprs_3.png" alt="fast_gprs_3.png" />
</p>
</div>
</section>
<section id="slide-org3c046a8">
<h3 id="org3c046a8"><span class="section-number-3">8.27.</span> Fast GPRS with \(P = \mathcal{N}(0, 1), Q = \mathcal{N}(1, 1/16)\)</h3>

<div id="org907e1a3" class="figure">
<p><img src="./img/fast_gprs/fast_gprs_4.png" alt="fast_gprs_4.png" />
</p>
</div>
</section>
<section id="slide-org36ada67">
<h3 id="org36ada67"><span class="section-number-3">8.28.</span> Fast GPRS with \(P = \mathcal{N}(0, 1), Q = \mathcal{N}(1, 1/16)\)</h3>

<div id="orgce5af81" class="figure">
<p><img src="./img/fast_gprs/fast_gprs_5.png" alt="fast_gprs_5.png" />
</p>
</div>

</section>
<section id="slide-orga76e8c5">
<h3 id="orga76e8c5"><span class="section-number-3">8.29.</span> Analysis of faster GPRS</h3>
<p class="fragment (appear)">
Now, encode search path \(\pi\).
</p>

<p class="fragment (appear)">
\(\mathbb{H}[\pi] \leq I[X; Y] + \log(I[X; Y] + 1) + \mathcal{O}(1)\)
</p>

<p class="fragment (appear)">
\(\mathbb{E}[\lvert\pi\rvert] = \mathcal{O}(I[X; Z])\)
</p>

<p class="fragment (appear)">
This is <b>optimal</b>.
</p>

</section>
<section id="slide-org62938e1">
<h2 id="org62938e1"><span class="section-number-2">9.</span> Take home message: GPRS</h2>
<ul>
<li class="fragment appear">GPRS is a rejection sampler using Poisson processes</li>
<li class="fragment appear">Can be used for relative entropy coding</li>
<li class="fragment appear">Has an optimally efficient variant for 1D, unimodal distributions</li>

</ul>

</section>
<section id="slide-orgb56d9c6">
<h2 id="orgb56d9c6"><span class="section-number-2">10.</span> Some recent results</h2>
<p class="fragment (appear)">
ü§î REC: A misnomer?
</p>

</section>
<section id="slide-org0a9f646">
<h3 id="org0a9f646"><span class="section-number-3">10.1.</span> Coding Efficiency Revisited</h3>
<p class="fragment (appear)">
REC coding efficiency:
\[
{\color{red} I[X; Y]} \leq \mathbb{H}[X \mid S] \leq {\color{red} I[X; Y]} + {\color{blue} \log (I[X; Y] + 1) + 4}
\]
</p>

<p class="fragment (appear)">
Doesn't collapse onto Shannon's source coding theorem.
</p>

</section>
<section id="slide-org100702e">
<h3 id="org100702e"><span class="section-number-3">10.2.</span> Rewriting the KL Divergence</h3>
<div class="fragment (appear)">
\begin{align}
D_{KL}[Q || P]
&= \int_\Omega \log \frac{dQ}{dP}(x) \, dQ(x) \\
&= \log e + \int_0^\infty \underbrace{\mathbb{P}_{Z \sim P}\left[ \frac{dQ}{dP}(Z) \geq h \right]}_{= w_P(h)} \cdot \log h \, dh
\end{align}

</div>

</section>
<section id="slide-orge84dbb7">
<h3 id="orge84dbb7"><span class="section-number-3">10.3.</span> A New Measure of Efficiency</h3>
<p class="fragment (appear)">
\[
D_{KL}[Q || P] = \log e - \int_0^\infty w_P(h) \log \frac{1}{h} \, dh
\]
</p>

<p class="fragment (appear)">
\[
D_{CS}[Q || P] = -\int_0^\infty w_P(h) \log w_P(h) \, dh
\]
</p>

</section>
<section id="slide-org2538ad2">
<h3 id="org2538ad2"><span class="section-number-3">10.4.</span> Properties of \(D_{CS}\)</h3>
<ol>
<li class="fragment appear">\(D_{CS}[Q || P] \geq 0\), equality when \(Q = P\).</li>
<li class="fragment appear">\(D_{CS}[\delta_x || P] = -\log P(x)\).</li>
<li class="fragment appear"><p>
In the rejection sampling setup (Goc &amp; F.):
</p>
<div>
\begin{align}
D_{KL}[Q || P] &\leq D_{CS}[Q || P] \\
&\leq \mathbb{H}[X \mid S, Y = y] \\
&\leq D_{CS}[Q || P] + \log(1 + e) \\
&\leq D_{KL}[Q || P] + \log(D_{KL}[Q || P] + 1) \\
& \quad\quad + \log(1 + e) + o(1)
\end{align}

</div></li>

</ol>

</section>
<section id="slide-org9138561">
<h3 id="org9138561"><span class="section-number-3">10.5.</span> Some Empirical Results I</h3>

<div id="org5888fd0" class="figure">
<p><img src="./img/new_results/laplace_divergences.png" alt="laplace_divergences.png" />
</p>
</div>

</section>
<section id="slide-orga0b875d">
<h3 id="orga0b875d"><span class="section-number-3">10.6.</span> Some Empirical Results II</h3>

<div id="org34ee26c" class="figure">
<p><img src="./img/new_results/gauss_1d_divergences.png" alt="gauss_1d_divergences.png" />
</p>
</div>

</section>
<section id="slide-org9ce4225">
<h3 id="org9ce4225"><span class="section-number-3">10.7.</span> Some Empirical Results III</h3>

<div id="orga79ebec" class="figure">
<p><img src="./img/new_results/gauss_nd_divergences.png" alt="gauss_nd_divergences.png" />
</p>
</div>


</section>
<section id="slide-org67b4eec">
<h2 id="org67b4eec"><span class="section-number-2">11.</span> References</h2>
<div class="outline-text-2" id="text-11">
</div>
</section>
<section id="slide-org5588020">
<h3 id="org5588020"><span class="section-number-3">11.1.</span> References I</h3>
<ul>
<li>E. Agustsson and L. Theis. "Universally quantized neural compression" In NeurIPS 2020.</li>
<li>C. Blundell, J. Cornebise, K. Kavukcuoglu and D. Wierstra. Weight uncertainty in neural network. In ICML 2015.</li>
<li>E. Dupont, A. Golinski, M. Alizadeh, Y. W. Teh and Arnaud Doucet. "COIN: compression with implicit neural representations" arXiv preprint arXiv:2103.03123, 2021.</li>

</ul>

</section>
<section id="slide-org908f830">
<h3 id="org908f830"><span class="section-number-3">11.2.</span> References II</h3>
<ul>
<li>G. F. ‚ÄúGreedy Poisson Rejection Sampling‚Äù NeurIPS 2023, to appear.</li>
<li>G. F.*, S. Markou*, and J. M. Hernandez-Lobato. "Fast relative entropy coding with A* coding". In ICML 2022.</li>
<li>D. Goc and G. F. ‚ÄúOn Channel Simulation Conjectures‚Äù unpublished.</li>

</ul>

</section>
<section id="slide-org3f51aeb">
<h3 id="org3f51aeb"><span class="section-number-3">11.3.</span> References III</h3>
<ul>
<li>Z. Guo*, G. F.*, J. He, Z. Chen and J. M. Hernandez Lobato, ‚ÄúCompression with Bayesian Implicit Neural Representations‚Äù NeurIPS 2023, to appear.</li>
<li>P. Harsha, R. Jain, D. McAllester, and J. Radhakrishnan, ‚ÄúThe communication complexity of correlation,‚Äù IEEE Transactions on Information Theory, vol. 56, no. 1, pp. 438‚Äì449, 2010.</li>
<li>M. Havasi, R. Peharz, and J. M. HernaÃÅndez-Lobato. "Minimal Random Code Learning: Getting Bits Back from Compressed Model Parameters" In ICLR 2019.</li>

</ul>

</section>
<section id="slide-org17822e8">
<h3 id="org17822e8"><span class="section-number-3">11.4.</span> References IV</h3>
<ul>
<li>J. He*, G. F.*, Z. Guo and J. M. Hernandez Lobato, ‚ÄúRECOMBINER: Robust and Enhanced Compression with Bayesian Implicit Neural Representations‚Äù unpublished.</li>
<li>C. T. Li and A. El Gamal, ‚ÄúStrong functional representation lemma and applications to coding theorems,‚Äù IEEE Transactions on Information Theory, vol. 64, no. 11, pp. 6967‚Äì6978, 2018.</li>

</ul>

</section>
<section id="slide-org03f0095">
<h3 id="org03f0095"><span class="section-number-3">11.5.</span> References V</h3>
<ul>
<li>L. Theis and E. Agustsson. On the advantages of stochastic encoders. arXiv preprint arXiv:2102.09270.</li>
<li>L. Theis, T. Salimans, M. D. Hoffman and F. Mentzer (2022). Lossy compression with Gaussian diffusion. arXiv preprint arXiv:2206.08889.</li>

</ul>

</section>
<section id="slide-orgf9151fe">
<h2 id="orgf9151fe"><span class="section-number-2">12.</span> Other material</h2>

<div id="orgd00dea7" class="figure">
<p><img src="./img/after_references/lossless_rec.png" alt="lossless_rec.png" />
</p>
</div>
</section>
</section>
</div>
</div>
<script src="https://cdn.jsdelivr.net/npm/reveal.js/dist/reveal.js"></script>
<script src="https://cdn.jsdelivr.net/npm/reveal.js/plugin/markdown/markdown.js"></script>
<script src="https://cdn.jsdelivr.net/npm/reveal.js/plugin/zoom/zoom.js"></script>
<script src="https://cdn.jsdelivr.net/npm/reveal.js/plugin/notes/notes.js"></script>


<script>
// Full list of configuration options available here:
// https://github.com/hakimel/reveal.js#configuration
Reveal.initialize({
plugins: [RevealMarkdown, RevealZoom, RevealNotes],
slideNumber:'c/t', transition:'none'
});

</script>
</body>
</html>
