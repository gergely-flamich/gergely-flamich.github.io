<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8"/>
<title>An Introduction to Relative Entropy Coding</title>
<meta name="author" content="Gergely Flamich"/>
<meta name="description" content=""/>
<meta name="keywords" content=""/>
<style type="text/css">
.underline { text-decoration: underline; }
</style>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/reveal.js/dist/reveal.css"/>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/reveal.js/dist/theme/white.css" id="theme"/>

<link rel="stylesheet" href="./presentation_styles.css"/>
<script type="text/javascript" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>
<div class="reveal">
<div class="slides">
<section id="sec-title-slide"><h2>An Introduction to Relative Entropy Coding</h2><h2></h2></br><h4>Gergely Flamich</h4><h4>18/10/2023</h4><h6>gergely-flamich.github.io</h6>
</section>

<section id="slide-org1fee5b2">
<h2 id="org1fee5b2"><span class="section-number-2">1.</span> Talk Overview</h2>
<aside class="notes">
<p>
quant usually perceived <b>fundamental</b> to TC
</p>

</aside>

<ol>
<li class="fragment appear">Transform coding &amp; problems with \(\lfloor \cdot \rceil\)</li>
<li class="fragment appear">What is REC?</li>
<li class="fragment appear">How can we use REC?</li>
<li class="fragment appear">An example of a REC algorithm</li>
<li class="fragment appear">Some recent results</li>

</ol>

</section>
<section id="slide-orgb7b8040">
<h2 id="orgb7b8040"><span class="section-number-2">2.</span> In Collaboration With</h2>
<img src="./img/collaborators/jiajun_he.jpg" width=23% >
<img src="./img/collaborators/zongyu_guo.jpg" width=23%>
<img src="./img/collaborators/daniel_goc.jpg" width=23%>
<img src="./img/collaborators/miguel_hernandez_lobato.png" width=23%>

</section>
<section id="slide-orgc42bfd0">
<h2 id="orgc42bfd0"><span class="section-number-2">3.</span> Motivation</h2>
<div class="outline-text-2" id="text-3">
</div>
</section>
<section id="slide-orgfd75196">
<h3 id="orgfd75196"><span class="section-number-3">3.1.</span> Example: Lossy Image Compression</h3>
<aside class="notes">
<ul>
<li>transform coding</li>
<li>REC: replacement for quant + EC</li>
<li>second part: example of transform</li>

</ul>

</aside>


<div id="org06ff11e" class="figure">
<p><img src="./img/jpeg_example/transform_encoding.png" alt="transform_encoding.png" class="fragment (appear)" />
</p>
</div>


<div id="org9ef5246" class="figure">
<p><img src="./img/jpeg_example/transform_decoding.png" alt="transform_decoding.png" class="fragment (appear)" />
</p>
</div>

</section>
<section id="slide-org3162b74">
<h3 id="org3162b74"><span class="section-number-3">3.2.</span> The Setup</h3>
<p class="fragment (appear)">
Get an image \(Y \sim P_Y\)
</p>

<p class="fragment (appear)">
\(\mathbb{H}[Y]\) bits is best we can do to compress \(Y\)
</p>

<div class="problem-list">

<ul>
<li class="fragment appear">\(\mathbb{H}[Y]\) might be infinite</li>
<li class="fragment appear">\(\mathbb{H}[Y]\) finite, but \(P_Y\) complicated</li>

</ul>

</div>

</section>
<section id="slide-org3f533b1">
<h3 id="org3f533b1"><span class="section-number-3">3.3.</span> The Transform</h3>
<p class="fragment (appear)">
\(X = f(Y)\)
</p>

<aside class="notes">
<ul>
<li>assume \(f\) maps into \(\mathbb{R}^D\)</li>
<li>invertible or approximately invertible</li>

</ul>

</aside>

<ul>
<li class="fragment appear">Pick \(f\) such that \(P_X\) or \(P_{X \mid Y}\) is "nice"
<ul>
<li>DCT</li>
<li>inference network of VAE</li>

</ul></li>
<li class="fragment appear">\(\mathbb{H}[X]\) might still be infinite</li>

</ul>

</section>
<section id="slide-orgcdc872d">
<h3 id="orgcdc872d"><span class="section-number-3">3.4.</span> Quantization + Entropy Coding</h3>
<p class="fragment (appear)">
\(\hat{X} = \lfloor X \rceil\)
</p>

<p class="fragment (appear)">
\(\mathbb{H}[\hat{X}] < \infty\)
</p>

<div class="problem-list">

<ul>
<li class="fragment appear">\(\lfloor \cdot \rceil\) not differentiable</li>
<li class="fragment appear">Don't have precise control over \(P_{\hat{X} \mid Y}\)</li>

</ul>

</div>


</section>
<section id="slide-orgae69df3">
<h2 id="orgae69df3"><span class="section-number-2">4.</span> What is Relative Entropy Coding?</h2>
<p class="fragment (appear)">
üí° <b>stochastic</b> alternative to \(\lfloor \cdot \rceil\) &amp; entropy coding
</p>

<aside class="notes">
<ul>
<li>Talk about my research only</li>
<li>won't mention DQ</li>

</ul>

</aside>


</section>
<section id="slide-orgdd68728">
<h3 id="orgdd68728"><span class="section-number-3">4.1.</span> Relative Entropy Coding</h3>
<aside class="notes">
<ul>
<li>\(\epsilon\) is an RV</li>
<li>lose information stochastically</li>
<li>setup is more general than this</li>

</ul>

</aside>

<div class="idea-list">
<ul>
<li class="fragment appear">\(X = f(Y) + \epsilon\)</li>
<li class="fragment appear">Encode \(X \sim P_{X \mid Y}\)</li>

</ul>
</div>

<p class="fragment (appear)">
<b>Pros:</b>
</p>

<div class="tick-list">
<ul>
<li class="fragment appear">Can use reparameterization trick!</li>
<li class="fragment appear">Precise control over \(P_{X \mid Y}\) via \(f\) and \(\epsilon\)!</li>

</ul>
</div>

<p class="fragment (appear)">
<b>But:</b>
</p>
<div class="problem-list">
<ul>
<li class="fragment appear">How do we encode \(X\)?</li>
<li class="fragment appear">How many bits do we need?</li>

</ul>
</div>

</section>
<section id="slide-orgca72c86">
<h3 id="orgca72c86"><span class="section-number-3">4.2.</span> Rough Idea for Achievability</h3>
<p class="fragment (appear)">
Communication problem between Alice and Bob, who:
</p>
<ul>
<li class="fragment appear">share their PRNG seed \(S\)</li>
<li class="fragment appear">share \(P_X\) and can easily sample from it</li>

</ul>

<p class="fragment (appear)">
<b>Alice</b>
</p>
<ol>
<li class="fragment appear">Simulates \(N\) samples \(X_1, \dots, X_N \sim P_X^{\otimes N}\)</li>
<li class="fragment appear">Picks \(K \in [1:N]\) such that \(P_{X_K} \approx P_{X \mid Y}\).</li>
<li class="fragment appear">Encodes \(K\) using \(\approx \log K\) bits.</li>

</ol>

<aside class="notes">
<ul>
<li>e.g. rejection sampling: always pick last sample</li>

</ul>

</aside>

</section>
<section id="slide-orgfbbd5c2">
<h3 id="orgfbbd5c2"><span class="section-number-3">4.3.</span> Coding Efficiency</h3>
<p class="fragment (appear)">
When common randomness \(S\) available, there exists an algorithm, such that (Li and El Gamal, 2017):
\[
{\color{red} I[X; Y]} \leq \mathbb{H}[X \mid S] \leq {\color{red} I[X; Y]} + {\color{blue} \log (I[X; Y] + 1) + 4}
\]
</p>

<p class="fragment (appear)">
\(I[X; Y]\) can be <b>finite</b> even when \(\mathbb{H}[X]\) is <b>infinite</b>!
</p>

</section>
<section id="slide-orgf75c1b7">
<h3 id="orgf75c1b7"><span class="section-number-3">4.4.</span> Time Complexity</h3>
<div class="fragment (appear)">
\begin{align}
\mathbb{E}[K] &\geq 2^{\mathbb{E}[\log K]} \\
&\geq 2^{\mathbb{H}[X \mid S] - 1} \\
&\geq 2^{I[X; Y] - 1} \\
\end{align}

</div>

<p class="fragment (appear)">
This is <b>THE</b> limitation of REC in practice currently
</p>

</section>
<section id="slide-org915e08b">
<h2 id="org915e08b"><span class="section-number-2">5.</span> How Can We Use Relative Entropy Coding?</h2>
<p class="fragment (appear)">
üí° Think of \(P_{X, Y}\) as a generative model!
</p>

</section>
<section id="slide-orgcdb2e0b">
<h3 id="orgcdb2e0b"><span class="section-number-3">5.1.</span> Lossy Compression with Realism Constraints</h3>
<aside class="notes">
<ul>
<li>not my work, but probably most important application of REC</li>

</ul>

</aside>

<p class="fragment (appear)">
Rate-Distortion trade-off
\[
R(D) = \min_{P_{\hat{Y} \mid Y}} I[Y; \hat{Y}]\,\, \text{s.t.}\,\, \mathbb{E}[\Delta(Y, \hat{Y})] \leq D
\]
</p>
<p class="fragment (appear)">
Rate-Distortion-Perception trade-off
</p>
<div class="fragment (appear)">
\begin{align}
R(D, P) = \min_{P_{\hat{Y} \mid Y}} &\, I[Y; \hat{Y}]\,\, \text{s.t.}\\
\mathbb{E}&[\Delta(Y, \hat{Y})] \leq D \,\,\text{and}\,\, d(P_Y, P_{\hat{Y}}) \leq P
\end{align} 

</div>

</section>
<section id="slide-org4f654bd">
<h3 id="org4f654bd"><span class="section-number-3">5.2.</span> Lossy Compression with Realism Constraints</h3>
<ul>
<li>Theis &amp; Agustsson (2021):
<ul>
<li>REC provably better than quantization.</li>

</ul></li>
<li>Theis et al. (2022):</li>

</ul>
<img src="./img/applications/diffC.png" class="r-stretch" data-transition="appear">

</section>
<section id="slide-org080fb3b">
<h3 id="org080fb3b"><span class="section-number-3">5.3.</span> Model Compression</h3>
<img src="./img/applications/variational_bnn.png" class="r-stretch">
<ul>
<li class="fragment appear">Dataset \(\mathcal{D} \sim P_{\mathcal{D}}\)</li>
<li class="fragment appear">NN \(f(w, x)\) with weights \(w\) with prior \(P_w\)</li>
<li class="fragment appear">Train weight posterior \(P_{w \mid \mathcal{D}}\) using ELBO</li>
<li class="fragment appear">Encode \(w \sim P_{w \mid \mathcal{D}}\) in \(I[w; \mathcal{D}]\) bits</li>

</ul>

<p class="fragment (appear)">
Image from Blundell et al. (2015)
</p>

</section>
<section id="slide-org29d746d">
<h3 id="org29d746d"><span class="section-number-3">5.4.</span> Model Compression</h3>
<p>
Havasi et al. (2018): MIRACLE
</p>
<img src="./img/applications/miracle.png" class="r-stretch">

</section>
<section id="slide-orgfbb8bae">
<h3 id="orgfbb8bae"><span class="section-number-3">5.5.</span> Data Compression with INRs</h3>
<img src="./img/applications/coin.png" class="r-stretch">
<p>
Image from Dupont et al. (2021)
</p>

<p class="fragment (appear)">
<b>Problem</b>: Post-training quantization severely impacts performance!
</p>

</section>
<section id="slide-orge542f23">
<h3 id="orge542f23"><span class="section-number-3">5.6.</span> Compress variational INRs!</h3>
<p class="fragment (appear)">
<b>COMBINER</b>: COMpression with Bayesian Implicit Neural Representations
</p>

<p class="fragment (appear)">
<b>RECOMBINER</b>: Robust and Enhanced COMBINER
</p>

<p class="fragment (appear)">
üí°Gradient descent is the transform!
</p>

</section>
<section id="slide-org07e378c">
<h3 id="org07e378c"><span class="section-number-3">5.7.</span> Compress variational INRs!</h3>
<img src="./img/applications/recombiner_img.png" width="100%">

</section>
<section id="slide-org1c6b6f0">
<h3 id="org1c6b6f0"><span class="section-number-3">5.8.</span> Compress variational INRs!</h3>
<img src="./img/applications/recombiner.png" width="100%">

</section>
<section id="slide-orgd067124">
<h2 id="orgd067124"><span class="section-number-2">6.</span> Current limitations of REC</h2>
<div class="cross-list">
<ul>
<li class="fragment appear">Too slow (Agustsson &amp; Theis, 2020):
<ul>
<li>Average runtime of any general REC algorithm must scale at least \(2^{I[X; Y]}\)</li>

</ul></li>
<li class="fragment appear">Too limited:
<ul>
<li>Uniforms only (Agustsson &amp; Theis, 2020)</li>
<li>1D unimodal distributions only (F., 2022)</li>

</ul></li>
<li class="fragment appear">Too much codelength overhead</li>

</ul>
</div>

<p class="fragment (appear)">
<b>Open problem:</b> \(\mathcal{O}(I[X; Y])\) runtime when both \(P_{Y \mid X}\) and \(P_Y\) are multivariate Gaussian?
</p>

</section>
<section id="slide-orgc895e2c">
<h2 id="orgc895e2c"><span class="section-number-2">7.</span> Take home message: Overview and Applications</h2>
<ul>
<li class="fragment appear">REC is a stochastic compression framework</li>
<li class="fragment appear">Alternative to quantization and entropy coding</li>
<li class="fragment appear">It finds applications in:
<ul>
<li>Lossy compression with realism constraints</li>
<li>Model compression</li>
<li>Compressing Bayesian INRs</li>

</ul></li>
<li class="fragment appear">Currently still too slow or limited</li>

</ul>

</section>
<section id="slide-org4e3ac54">
<h2 id="org4e3ac54"><span class="section-number-2">8.</span> Greedy Poisson Rejection Sampling</h2>
<div class="outline-text-2" id="text-8">
</div>
</section>
<section id="slide-orge11d85d">
<h3 id="orge11d85d"><span class="section-number-3">8.1.</span> Recap of the Problem</h3>
<p class="fragment (appear)">
Correlated r.v.s \(X, Y \sim P_{X, Y}\)
</p>

<p class="fragment (appear)">
Alice receives \(Y \sim P_Y\)
</p>

<p class="fragment (appear)">
Bob wants to simulate \(X \sim P_{X \mid Y}\)
</p>

<p class="fragment (appear)">
Share common randomness \(S\)
</p>

<p class="fragment (appear)">
<b>Shorthand:</b> \(P = P_X\), \(Q = P_{X \mid Y}\)
</p>


</section>
<section id="slide-orgb46dacb">
<h3 id="orgb46dacb"><span class="section-number-3">8.2.</span> Poisson Processes</h3>
<ul>
<li class="fragment appear">Collection of random points in space</li>
<li class="fragment appear">Focus on spatio-temporal processes on \(\mathbb{R}^D \times \mathbb{R}^+\)</li>
<li class="fragment appear">Exponential inter-arrival times</li>
<li class="fragment appear">Spatial distribution \(P_{X \mid T}\)</li>
<li class="fragment appear">We will pick it as the common randomness!</li>

</ul>

</section>
<section id="slide-orgc8b8171">
<h3 id="orgc8b8171"><span class="section-number-3">8.3.</span> Poisson Processes</h3>
<img src="./img/pp_alg.png" class="r-stretch">

</section>
<section id="slide-org4b4846d">
<h3 id="org4b4846d"><span class="section-number-3">8.4.</span> Example with \(P_{X \mid T} = \mathcal{N}(0, 1)\)</h3>

<div id="org0937b6b" class="figure">
<p><img src="./img/pp/empty_pp.png" alt="empty_pp.png" />
</p>
</div>

</section>
<section id="slide-org6b532a1">
<h3 id="org6b532a1"><span class="section-number-3">8.5.</span> Example with \(P_{X \mid T} = \mathcal{N}(0, 1)\)</h3>

<div id="org287fb61" class="figure">
<p><img src="./img/pp/pp_t1.png" alt="pp_t1.png" />
</p>
</div>

</section>
<section id="slide-org33eb550">
<h3 id="org33eb550"><span class="section-number-3">8.6.</span> Example with \(P_{X \mid T} = \mathcal{N}(0, 1)\)</h3>

<div id="orga4540da" class="figure">
<p><img src="./img/pp/pp_x1.png" alt="pp_x1.png" />
</p>
</div>

</section>
<section id="slide-orge6cfdd1">
<h3 id="orge6cfdd1"><span class="section-number-3">8.7.</span> Example with \(P_{X \mid T} = \mathcal{N}(0, 1)\)</h3>

<div id="org65a3283" class="figure">
<p><img src="./img/pp/pp_t1_x1.png" alt="pp_t1_x1.png" />
</p>
</div>

</section>
<section id="slide-org5a67003">
<h3 id="org5a67003"><span class="section-number-3">8.8.</span> Example with \(P_{X \mid T} = \mathcal{N}(0, 1)\)</h3>

<div id="orge7634eb" class="figure">
<p><img src="./img/pp/pp_t2.png" alt="pp_t2.png" />
</p>
</div>

</section>
<section id="slide-org1c4db6a">
<h3 id="org1c4db6a"><span class="section-number-3">8.9.</span> Example with \(P_{X \mid T} = \mathcal{N}(0, 1)\)</h3>

<div id="org94cecb0" class="figure">
<p><img src="./img/pp/pp_x2.png" alt="pp_x2.png" />
</p>
</div>

</section>
<section id="slide-org67af4f7">
<h3 id="org67af4f7"><span class="section-number-3">8.10.</span> Example with \(P_{X \mid T} = \mathcal{N}(0, 1)\)</h3>

<div id="orgb080c65" class="figure">
<p><img src="./img/pp/pp_t2_x2.png" alt="pp_t2_x2.png" />
</p>
</div>

</section>
<section id="slide-orgdc94858">
<h3 id="orgdc94858"><span class="section-number-3">8.11.</span> Example with \(P_{X \mid T} = \mathcal{N}(0, 1)\)</h3>

<div id="org5c9697e" class="figure">
<p><img src="./img/pp/pp_sim.png" alt="pp_sim.png" />
</p>
</div>


</section>
<section id="slide-orgd880023">
<h3 id="orgd880023"><span class="section-number-3">8.12.</span> Greedy Poisson Rejection Sampling</h3>
<p>
üí° Delete some of the points, encode index of the first point that remains
</p>

</section>
<section id="slide-orgde31acc">
<h3 id="orgde31acc"><span class="section-number-3">8.13.</span> GPRS with \(P = \mathcal{N}(0, 1), Q = \mathcal{N}(1, 1/16)\)</h3>

<div id="org11a77b1" class="figure">
<p><img src="./img/gprs/gprs_0.png" alt="gprs_0.png" />
</p>
</div>

</section>
<section id="slide-org1bca9d3">
<h3 id="org1bca9d3"><span class="section-number-3">8.14.</span> GPRS with \(P = \mathcal{N}(0, 1), Q = \mathcal{N}(1, 1/16)\)</h3>

<div id="org31b46a5" class="figure">
<p><img src="./img/gprs/gprs_1.png" alt="gprs_1.png" />
</p>
</div>

</section>
<section id="slide-orgbcfa4b8">
<h3 id="orgbcfa4b8"><span class="section-number-3">8.15.</span> GPRS with \(P = \mathcal{N}(0, 1), Q = \mathcal{N}(1, 1/16)\)</h3>

<div id="orgf9563b2" class="figure">
<p><img src="./img/gprs/gprs_2.png" alt="gprs_2.png" />
</p>
</div>

</section>
<section id="slide-orga347e4c">
<h3 id="orga347e4c"><span class="section-number-3">8.16.</span> GPRS with \(P = \mathcal{N}(0, 1), Q = \mathcal{N}(1, 1/16)\)</h3>

<div id="org25ad345" class="figure">
<p><img src="./img/gprs/gprs_3.png" alt="gprs_3.png" />
</p>
</div>

</section>
<section id="slide-org2816f39">
<h3 id="org2816f39"><span class="section-number-3">8.17.</span> GPRS with \(P = \mathcal{N}(0, 1), Q = \mathcal{N}(1, 1/16)\)</h3>

<div id="org03f437e" class="figure">
<p><img src="./img/gprs/gprs_4.png" alt="gprs_4.png" />
</p>
</div>

</section>
<section id="slide-orgfd526d3">
<h3 id="orgfd526d3"><span class="section-number-3">8.18.</span> GPRS with \(P = \mathcal{N}(0, 1), Q = \mathcal{N}(1, 1/16)\)</h3>

<div id="orgc42d19a" class="figure">
<p><img src="./img/gprs/gprs_5.png" alt="gprs_5.png" />
</p>
</div>

</section>
<section id="slide-orgcb19cd8">
<h3 id="orgcb19cd8"><span class="section-number-3">8.19.</span> GPRS with \(P = \mathcal{N}(0, 1), Q = \mathcal{N}(1, 1/16)\)</h3>

<div id="org9d998e8" class="figure">
<p><img src="./img/gprs/gprs_accept.png" alt="gprs_accept.png" />
</p>
</div>


</section>
<section id="slide-org8e0048d">
<h3 id="org8e0048d"><span class="section-number-3">8.20.</span> How to find the graph?</h3>
<p class="fragment (appear)">
\[
\varphi(x) = \int_0^{\frac{dQ}{dP}(x)} \frac{1}{w_Q(\eta) - \eta \cdot w_P(\eta)} \, d\eta,
\]
</p>
<p class="fragment (appear)">
where
\[
w_P(h) = \mathbb{P}_{Z \sim P}\left[\frac{dQ}{dP}(Z) \geq h \right]
\]
\[
w_Q(h) = \mathbb{P}_{Z \sim Q}\left[\frac{dQ}{dP}(Z) \geq h \right]
\]
</p>

</section>
<section id="slide-org3700fcc">
<h3 id="org3700fcc"><span class="section-number-3">8.21.</span> Analysis of GPRS</h3>
<p class="fragment (appear)">
<b>Codelength</b>
</p>
<div class="fragment (appear)">
\begin{align}
\mathbb{H}[X \mid S] &\leq I[X; Y] + \log (I[X; Y] + 1) \\
&\quad + 2 + \frac{1}{1 + I[X; Y] \cdot \ln 2}
\end{align}

</div>

<p class="fragment (appear)">
<b>Runtime</b>
</p>

<p class="fragment (appear)">
\[
\mathbb{E}[K \mid Y] = \exp(D_{\infty}[P_{X \mid Y} \Vert P_X])
\]
</p>

</section>
<section id="slide-org83eab9c">
<h3 id="org83eab9c"><span class="section-number-3">8.22.</span> Speeding up GPRS</h3>

<div id="org5618859" class="figure">
<p><img src="./img/gprs/gprs_accept.png" alt="gprs_accept.png" />
</p>
</div>

</section>
<section id="slide-orgf2c2c79">
<h3 id="orgf2c2c79"><span class="section-number-3">8.23.</span> Fast GPRS with \(P = \mathcal{N}(0, 1), Q = \mathcal{N}(1, 1/16)\)</h3>

<div id="org7af78cb" class="figure">
<p><img src="./img/fast_gprs/fast_gprs_0.png" alt="fast_gprs_0.png" />
</p>
</div>
</section>
<section id="slide-org88614e9">
<h3 id="org88614e9"><span class="section-number-3">8.24.</span> Fast GPRS with \(P = \mathcal{N}(0, 1), Q = \mathcal{N}(1, 1/16)\)</h3>

<div id="org6b20770" class="figure">
<p><img src="./img/fast_gprs/fast_gprs_1.png" alt="fast_gprs_1.png" />
</p>
</div>
</section>
<section id="slide-org49ee936">
<h3 id="org49ee936"><span class="section-number-3">8.25.</span> Fast GPRS with \(P = \mathcal{N}(0, 1), Q = \mathcal{N}(1, 1/16)\)</h3>

<div id="orga75f9e3" class="figure">
<p><img src="./img/fast_gprs/fast_gprs_2.png" alt="fast_gprs_2.png" />
</p>
</div>
</section>
<section id="slide-org4d49dd8">
<h3 id="org4d49dd8"><span class="section-number-3">8.26.</span> Fast GPRS with \(P = \mathcal{N}(0, 1), Q = \mathcal{N}(1, 1/16)\)</h3>

<div id="orga838437" class="figure">
<p><img src="./img/fast_gprs/fast_gprs_3.png" alt="fast_gprs_3.png" />
</p>
</div>
</section>
<section id="slide-org1c9b78b">
<h3 id="org1c9b78b"><span class="section-number-3">8.27.</span> Fast GPRS with \(P = \mathcal{N}(0, 1), Q = \mathcal{N}(1, 1/16)\)</h3>

<div id="orga59e5cd" class="figure">
<p><img src="./img/fast_gprs/fast_gprs_4.png" alt="fast_gprs_4.png" />
</p>
</div>
</section>
<section id="slide-orgc41b413">
<h3 id="orgc41b413"><span class="section-number-3">8.28.</span> Fast GPRS with \(P = \mathcal{N}(0, 1), Q = \mathcal{N}(1, 1/16)\)</h3>

<div id="org9188357" class="figure">
<p><img src="./img/fast_gprs/fast_gprs_5.png" alt="fast_gprs_5.png" />
</p>
</div>

</section>
<section id="slide-org16e39cb">
<h3 id="org16e39cb"><span class="section-number-3">8.29.</span> Analysis of faster GPRS</h3>
<p class="fragment (appear)">
Now, encode search path \(\pi\).
</p>

<p class="fragment (appear)">
\(\mathbb{H}[\pi] \leq I[X; Y] + \log(I[X; Y] + 1) + \mathcal{O}(1)\)
</p>

<p class="fragment (appear)">
\(\mathbb{E}[\lvert\pi\rvert] = \mathcal{O}(I[X; Z])\)
</p>

<p class="fragment (appear)">
This is <b>optimal</b>.
</p>

</section>
<section id="slide-orgef148bc">
<h2 id="orgef148bc"><span class="section-number-2">9.</span> Take home message: GPRS</h2>
<ul>
<li class="fragment appear">GPRS is a rejection sampler using Poisson processes</li>
<li class="fragment appear">Can be used for relative entropy coding</li>
<li class="fragment appear">Has an optimally efficient variant for 1D, unimodal distributions</li>

</ul>

</section>
<section id="slide-org90fe0f9">
<h2 id="org90fe0f9"><span class="section-number-2">10.</span> Some recent results</h2>
<p class="fragment (appear)">
ü§î REC: A misnomer?
</p>

</section>
<section id="slide-org7ecf91a">
<h3 id="org7ecf91a"><span class="section-number-3">10.1.</span> Coding Efficiency Revisited</h3>
<p class="fragment (appear)">
REC coding efficiency:
\[
{\color{red} I[X; Y]} \leq \mathbb{H}[X \mid S] \leq {\color{red} I[X; Y]} + {\color{blue} \log (I[X; Y] + 1) + 4}
\]
</p>

<p class="fragment (appear)">
Doesn't collapse onto Shannon's source coding theorem.
</p>

</section>
<section id="slide-org5d93b60">
<h3 id="org5d93b60"><span class="section-number-3">10.2.</span> Rewriting the KL Divergence</h3>
<div class="fragment (appear)">
\begin{align}
D_{KL}[Q || P]
&= \int_\Omega \frac{dQ}{dP}(x) \cdot \log \frac{dQ}{dP}(x) \, dP(x) \\
&= \log e + \int_0^\infty \underbrace{\mathbb{P}_{Z \sim P}\left[ \frac{dQ}{dP}(Z) \geq h \right]}_{= w_P(h)} \cdot \log h \, dh
\end{align}

</div>

</section>
<section id="slide-org67ed7ff">
<h3 id="org67ed7ff"><span class="section-number-3">10.3.</span> A New Measure of Efficiency</h3>
<p class="fragment (appear)">
\[
D_{KL}[Q || P] = \log e - \int_0^\infty w_P(h) \log \frac{1}{h} \, dh
\]
</p>

<p class="fragment (appear)">
\[
D_{CS}[Q || P] = -\int_0^\infty w_P(h) \log w_P(h) \, dh
\]
</p>

</section>
<section id="slide-orgc6f05b3">
<h3 id="orgc6f05b3"><span class="section-number-3">10.4.</span> Properties of \(D_{CS}\)</h3>
<ol>
<li class="fragment appear">\(D_{CS}[Q || P] \geq 0\), equality when \(Q = P\).</li>
<li class="fragment appear">\(D_{CS}[\delta_x || P] = -\log P(x)\).</li>
<li class="fragment appear"><p>
In the rejection sampling setup (Goc &amp; F.):
</p>
<div>
\begin{align}
D_{KL}[Q || P] &\leq D_{CS}[Q || P] \\
&\ {\color{red} \leq}\ \mathbb{H}[X \mid S, Y = y] \\
&\ {\color{blue} \leq}\ D_{CS}[Q || P] + \log(1 + e) \\
&\leq D_{KL}[Q || P] + \log(D_{KL}[Q || P] + 1) \\
& \quad\quad + \log(1 + e) + o(1)
\end{align}

</div></li>

</ol>

</section>
<section id="slide-org04551f3">
<h3 id="org04551f3"><span class="section-number-3">10.5.</span> Some Empirical Results I</h3>
<div class="fragment (appear)">
\begin{align}
D_{KL}[\mathcal{L}(0, b) || \mathcal{L}(0, 1)] &= b - \ln b - 1 \\
D_{CS}[\mathcal{L}(0, b) || \mathcal{L}(0, 1)] &= b - \psi\left(\frac{1}{b}\right) + \gamma - 1
\end{align}

</div>

<div id="orgbd40b14" class="figure">
<p><img src="./img/new_results/laplace_divergences.png" alt="laplace_divergences.png" class="fragment (appear)" />
</p>
</div>

</section>
<section id="slide-org2208417">
<h3 id="org2208417"><span class="section-number-3">10.6.</span> Some Empirical Results II</h3>

<div id="org9ebecff" class="figure">
<p><img src="./img/new_results/gauss_1d_divergences.png" alt="gauss_1d_divergences.png" />
</p>
</div>

</section>
<section id="slide-org3f5e2fd">
<h3 id="org3f5e2fd"><span class="section-number-3">10.7.</span> Some Empirical Results III</h3>

<div id="org32c6a91" class="figure">
<p><img src="./img/new_results/gauss_nd_divergences.png" alt="gauss_nd_divergences.png" />
</p>
</div>


</section>
<section id="slide-org24d0686">
<h2 id="org24d0686"><span class="section-number-2">11.</span> References</h2>
<div class="outline-text-2" id="text-11">
</div>
</section>
<section id="slide-orga53b843">
<h3 id="orga53b843"><span class="section-number-3">11.1.</span> References I</h3>
<ul>
<li>E. Agustsson and L. Theis. "Universally quantized neural compression" In NeurIPS 2020.</li>
<li>C. Blundell, J. Cornebise, K. Kavukcuoglu and D. Wierstra. Weight uncertainty in neural network. In ICML 2015.</li>
<li>E. Dupont, A. Golinski, M. Alizadeh, Y. W. Teh and Arnaud Doucet. "COIN: compression with implicit neural representations" arXiv preprint arXiv:2103.03123, 2021.</li>

</ul>

</section>
<section id="slide-orgd2c18cb">
<h3 id="orgd2c18cb"><span class="section-number-3">11.2.</span> References II</h3>
<ul>
<li>G. F. ‚ÄúGreedy Poisson Rejection Sampling‚Äù NeurIPS 2023, to appear.</li>
<li>G. F.*, S. Markou*, and J. M. Hernandez-Lobato. "Fast relative entropy coding with A* coding". In ICML 2022.</li>
<li>D. Goc and G. F. ‚ÄúOn Channel Simulation Conjectures‚Äù unpublished.</li>

</ul>

</section>
<section id="slide-orgbabf116">
<h3 id="orgbabf116"><span class="section-number-3">11.3.</span> References III</h3>
<ul>
<li>Z. Guo*, G. F.*, J. He, Z. Chen and J. M. Hernandez Lobato, ‚ÄúCompression with Bayesian Implicit Neural Representations‚Äù NeurIPS 2023, to appear.</li>
<li>P. Harsha, R. Jain, D. McAllester, and J. Radhakrishnan, ‚ÄúThe communication complexity of correlation,‚Äù IEEE Transactions on Information Theory, vol. 56, no. 1, pp. 438‚Äì449, 2010.</li>
<li>M. Havasi, R. Peharz, and J. M. HernaÃÅndez-Lobato. "Minimal Random Code Learning: Getting Bits Back from Compressed Model Parameters" In ICLR 2019.</li>

</ul>

</section>
<section id="slide-org2c260b1">
<h3 id="org2c260b1"><span class="section-number-3">11.4.</span> References IV</h3>
<ul>
<li>J. He*, G. F.*, Z. Guo and J. M. Hernandez Lobato, ‚ÄúRECOMBINER: Robust and Enhanced Compression with Bayesian Implicit Neural Representations‚Äù unpublished.</li>
<li>C. T. Li and A. El Gamal, ‚ÄúStrong functional representation lemma and applications to coding theorems,‚Äù IEEE Transactions on Information Theory, vol. 64, no. 11, pp. 6967‚Äì6978, 2018.</li>

</ul>

</section>
<section id="slide-org9b24fac">
<h3 id="org9b24fac"><span class="section-number-3">11.5.</span> References V</h3>
<ul>
<li>L. Theis and E. Agustsson. On the advantages of stochastic encoders. arXiv preprint arXiv:2102.09270.</li>
<li>L. Theis, T. Salimans, M. D. Hoffman and F. Mentzer (2022). Lossy compression with Gaussian diffusion. arXiv preprint arXiv:2206.08889.</li>

</ul>

</section>
<section id="slide-org2d27a71">
<h2 id="org2d27a71"><span class="section-number-2">12.</span> Other material</h2>

<div id="org6d3b77d" class="figure">
<p><img src="./img/after_references/lossless_rec.png" alt="lossless_rec.png" />
</p>
</div>
</section>
</section>
</div>
</div>
<script src="https://cdn.jsdelivr.net/npm/reveal.js/dist/reveal.js"></script>
<script src="https://cdn.jsdelivr.net/npm/reveal.js/plugin/markdown/markdown.js"></script>
<script src="https://cdn.jsdelivr.net/npm/reveal.js/plugin/zoom/zoom.js"></script>
<script src="https://cdn.jsdelivr.net/npm/reveal.js/plugin/notes/notes.js"></script>


<script>
// Full list of configuration options available here:
// https://github.com/hakimel/reveal.js#configuration
Reveal.initialize({
plugins: [RevealMarkdown, RevealZoom, RevealNotes],
slideNumber:'c/t', transition:'none'
});

</script>
</body>
</html>
